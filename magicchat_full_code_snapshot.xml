<file_tree>
/Users/neonvoid/Library/Mobile Documents/com~apple~CloudDocs/Documents/Projekt/River/River Resources/Code/magic_chat-local
├── magic_chat.py
├── temp
├── ├── context
├── ├── ├── context_nordicequation.txt
├── ├── ├── context_wlaevent.txt
├── ├── ├── context_playground.txt
├── ├── ├── context_main.txt
├── ├── └── context_roundtable.txt
├── ├── system-prompt
├── ├── ├── system-prompt_nordicequation.md
├── ├── ├── system-prompt_playground.md
├── ├── ├── system-prompt_roundtable.md
├── ├── ├── system-prompt_main.md
├── ├── ├── system-prompt.md
├── ├── └── system-prompt_wlaevent.md
├── ├── docs
├── ├── ├── tne-gathering-may-invitation.txt
├── ├── └── tne-partners-dec18.txt
├── ├── prompt
├── ├── ├── system-prompt_playground.md
├── ├── ├── system-prompt_roundtable.md
├── ├── ├── system-prompt_main.md
├── ├── ├── system-prompt.md
├── ├── └── system-prompt_wlaevent.md
├── ├── chats
├── ├── └── chat_nordicequation_20241204_100329.txt
├── └── downloads
├── └── ├── summary_uID-0112_oID-River_sID-f410ca1f-e7e2-4046-826a-4080f97d1b6a_TS-20241108_131015.txt
├── └── ├── system-prompt_nordicequation.md
├── └── ├── context_nordicequation.txt
├── └── ├── analysis_uID-0112_oID-River_sID-f410ca1f-e7e2-4046-826a-4080f97d1b6a_TS-20241108_131015.txt
├── └── ├── transcript_20241113-125316_uID-0112_oID-River_aID-River_sID-b32ad2a3-2900-49a6-9678-49601c4e32ad (6).txt
├── └── ├── transcript_uID-0112_oID-River_sID-9ea9fabb-6360-4d68-b170-8179ec108ed6_TS-20241120_100419 (2).txt
├── └── ├── chat_nordicequation_20241204_100329.txt
├── └── ├── transcript_20241113-125316_uID-0112_oID-River_aID-River_sID-b32ad2a3-2900-49a6-9678-49601c4e32ad (7).txt
├── └── ├── frameworks.txt
├── └── ├── insights_20241113-142215_uID-0112_oID-River_sID-wla.json
├── └── ├── summary_uID-0112_oID-River_sID-All-Data_TS-20241121_093000.txt
├── └── ├── transcript_uID-0112_oID-River_sID-a98a9903-dd6d-42bb-b600-084e57121857_TS-20241108_081400.txt
├── └── ├── transcript_uID-0112_oID-River_sID-8a849442-6280-45b0-8eda-fc43fdfdd468_TS-20241204_090928.txt
├── └── ├── transcript_20241113-130733_uID-0112_oID-River_aID-River_sID-527e5520-9522-4dbc-ba36-a4cef09adb60.txt
├── └── ├── transcript_20241115-105514_orgID-River_teamID-RiverTeam_userID-0112_eventID-MainEvent_agentID-Main_sID-2fd249c8-7486-43df-8111-6e9b8d8d41ff (1).txt
├── └── ├── transcript_uID-0112_oID-River_sID-ab8d29de-dbc1-4f06-8948-029f3426d14d_TS-20241203_090807-B.txt
├── └── ├── transcript_20241113-130733_uID-0112_oID-River_aID-River_sID-527e5520-9522-4dbc-ba36-a4cef09adb60 (1).txt
├── └── ├── analysis_uID-0112_oID-River_sID-01_TS-20241108_103000 copy 2.txt
├── └── ├── transcript_20241113-125316_uID-0112_oID-River_aID-River_sID-b32ad2a3-2900-49a6-9678-49601c4e32ad (1).txt
├── └── ├── summary_River Playground logs Nov 7th 2024.txt
├── └── ├── transcript_20241113-125316_uID-0112_oID-River_aID-River_sID-b32ad2a3-2900-49a6-9678-49601c4e32ad (2).txt
├── └── ├── summary_uID-0112_oID-River_sID-01_TS-20241108_103000 copy.txt
├── └── ├── summary_uID-0112_oID-River_sID-Playground_TS-20211120.txt
├── └── ├── analysis_uID-0112_oID-River_sID-a98a9903-dd6d-42bb-b600-084e57121857_TS-20241108_081400.txt
├── └── ├── Fabric 241121.txt
├── └── ├── transcript_20241113-125316_uID-0112_oID-River_aID-River_sID-b32ad2a3-2900-49a6-9678-49601c4e32ad.txt
├── └── ├── transcript_20241113-130733_uID-0112_oID-River_aID-River_sID-527e5520-9522-4dbc-ba36-a4cef09adb60 (2).txt
├── └── ├── transcript_20241115-110342_uID-0112_oID-River_sID-47128fd2-485f-45dd-9220-b8f4317a7d15.txt
├── └── ├── transcript_20241113-125316_uID-0112_oID-River_aID-River_sID-b32ad2a3-2900-49a6-9678-49601c4e32ad (3).txt
├── └── ├── transcript_20241115-105514_orgID-River_teamID-RiverTeam_userID-0112_eventID-MainEvent_agentID-Main_sID-2fd249c8-7486-43df-8111-6e9b8d8d41ff.txt
├── └── ├── transcript_uID-0112_oID-River_sID-8a849442-6280-45b0-8eda-fc43fdfdd468_TS-20241204_090928-B.txt
├── └── ├── transcript_uID-0112_oID-River_sID-87c62e1a-7890-46b5-884e-764dbb22751d_TS-20241121_135252.txt
├── └── ├── transcript_20241113-012428_uID-0112_oID-River_sID-01ef7ba3-4d67-49b9-8248-c08b4a080d14 (2).txt
├── └── ├── transcript_uID-0112_oID-River_sID-87c62e1a-7890-46b5-884e-764dbb22751d_TS-20241121_135252 (1).txt
├── └── ├── MMM.txt
├── └── ├── transcript_20241112-160000_uID-0112_oID-River_sID-00.txt
├── └── ├── transcript_uID-0112_oID-River_sID-f410ca1f-e7e2-4046-826a-4080f97d1b6a_TS-20241108_131015.txt
├── └── ├── transcript_20241113-125316_uID-0112_oID-River_aID-River_sID-b32ad2a3-2900-49a6-9678-49601c4e32ad (4).txt
├── └── ├── transcript_20241113-125316_uID-0112_oID-River_aID-River_sID-b32ad2a3-2900-49a6-9678-49601c4e32ad (5).txt
├── └── ├── 241114 Patrik Nyström.txt
├── └── ├── transcript_uID-0112_oID-River_sID-01_TS-20241108_103000.txt
├── └── ├── summary_20241112-160000_uID-0112_oID-River_sID-00.txt
├── └── └── Inför Fabric:Nordic Equation.txt
├── config.py
├── models.py
├── requirements.txt
├── web
├── ├── transcript.py
├── ├── s3_utils.py
├── ├── static
├── ├── ├── images
├── ├── ├── └── river_bg01.jpg
├── ├── └── gradient_themes.css
├── ├── web_chat.py
├── └── templates
├── └── ├── index.html
├── └── └── index_v1.html
├── system_prompt_standard.txt
├── system_prompt_wlaevent.txt
├── agents
├── utils
├── └── transcript_utils.py
├── docs
├── ├── context
├── ├── ├── context_River_Main.txt
├── ├── ├── context_River.txt
├── ├── ├── context_River_Roundtable.txt
├── ├── ├── context_River_Playground.txt
├── ├── └── context_WorklifeAcademy-River-EdshageEkman.txt
├── ├── archived prompts
├── ├── └── system_prompt_wlaevent-en.txt
├── └── frameworks
├── └── ├── frameworks.txt
├── └── └── frameworks_v1.txt
├── claude_chat.log
├── system_prompt_playground.txt
├── logs
├── ├── claude_analyzer.log
├── ├── claude_chat copy.log
├── └── claude_chat.log
├── ai_chat.log
├── magicchat_full_code_snapshot.xml
├── system_prompt_main.txt
└── system_prompt_roundtable.txt
</file_tree>

<file_contents>
File: /Users/neonvoid/Library/Mobile Documents/com~apple~CloudDocs/Documents/Projekt/River/River Resources/Code/magic_chat-local/web/transcript.py
```py
"""Transcript handling utilities for the web chat application."""
import os
import boto3
from datetime import datetime

# S3 configuration
AWS_S3_BUCKET = os.getenv('AWS_S3_BUCKET', 'aiademomagicaudio')

def get_latest_transcript_file(agent_name):
    """Get the latest transcript file for an agent."""
    try:
        s3 = boto3.client('s3')
        prefix = f'organizations/river/agents/{agent_name}/transcripts/'
        
        # List objects in the transcript directory
        response = s3.list_objects_v2(
            Bucket=AWS_S3_BUCKET,
            Prefix=prefix
        )
        
        if 'Contents' not in response:
            return None
            
        # Find the most recent file
        latest = None
        latest_time = None
        
        for obj in response['Contents']:
            if obj['Key'].endswith('.txt'):
                if latest is None or obj['LastModified'] > latest_time:
                    latest = obj['Key']
                    latest_time = obj['LastModified']
        
        return latest
    except Exception as e:
        print(f"Error getting latest transcript: {e}")
        return None

def read_new_transcript_content(transcript_state, agent_name):
    """Read new content from the transcript file."""
    if not transcript_state:
        return None
        
    try:
        s3 = boto3.client('s3')
        current_file = get_latest_transcript_file(agent_name)
        
        if not current_file:
            return None
            
        # Check if this is a new file
        if current_file != transcript_state.last_file:
            transcript_state.last_file = current_file
            transcript_state.last_position = 0
            
        # Get the file content from the last position
        response = s3.get_object(
            Bucket=AWS_S3_BUCKET,
            Key=current_file,
            Range=f'bytes={transcript_state.last_position}-'
        )
        
        new_content = response['Body'].read().decode('utf-8')
        if new_content:
            transcript_state.last_position += len(new_content.encode('utf-8'))
            return new_content
            
        return None
    except Exception as e:
        print(f"Error reading transcript: {e}")
        return None

```

File: /Users/neonvoid/Library/Mobile Documents/com~apple~CloudDocs/Documents/Projekt/River/River Resources/Code/magic_chat-local/web/s3_utils.py
```py
"""S3 utilities for the web chat application."""
import os
import boto3
from datetime import datetime
import json
import logging

# S3 configuration
AWS_S3_BUCKET = os.getenv('AWS_S3_BUCKET', 'aiademomagicaudio')

def read_file_content(s3_key, file_name):
    """Read content from an S3 file."""
    try:
        s3 = boto3.client('s3')
        obj = s3.get_object(Bucket=AWS_S3_BUCKET, Key=s3_key)
        return obj['Body'].read().decode('utf-8')
    except Exception as e:
        print(f"Error reading {file_name} from S3: {e}")
        return None

def save_chat_to_s3(chat_history, filename, agent_name):
    """Save chat history to S3."""
    try:
        s3 = boto3.client('s3')
        chat_key = f'organizations/river/agents/{agent_name}/chats/{filename}'
        
        # Convert chat history to JSON string
        chat_json = json.dumps({
            'messages': chat_history,
            'timestamp': datetime.now().isoformat()
        })
        
        # Upload to S3
        s3.put_object(
            Bucket=AWS_S3_BUCKET,
            Key=chat_key,
            Body=chat_json.encode('utf-8')
        )
        return True
    except Exception as e:
        print(f"Error saving chat to S3: {e}")
        return False

def load_existing_chats_from_s3(agent_name, max_chats=5):
    """Load existing chat histories from S3."""
    try:
        s3 = boto3.client('s3')
        prefix = f'organizations/river/agents/{agent_name}/chats/'
        
        # List chat files
        response = s3.list_objects_v2(
            Bucket=AWS_S3_BUCKET,
            Prefix=prefix
        )
        
        if 'Contents' not in response:
            return []
            
        # Sort by last modified time
        chat_files = sorted(
            response['Contents'],
            key=lambda x: x['LastModified'],
            reverse=True
        )[:max_chats]
        
        # Load chat contents
        chats = []
        for file in chat_files:
            content = read_file_content(file['Key'], 'chat history')
            if content:
                try:
                    chat_data = json.loads(content)
                    chats.append(chat_data)
                except json.JSONDecodeError:
                    print(f"Error decoding chat file {file['Key']}")
                    
        return chats
    except Exception as e:
        print(f"Error loading chats from S3: {e}")
        return []

def summarize_text(text, max_length=100):
    """Create a brief summary of text."""
    if not text:
        return ""
    words = text.split()
    if len(words) <= max_length:
        return text
    return " ".join(words[:max_length]) + "..."

def find_file_by_base(base_path, description):
    """Find a file by its base path, ignoring extension."""
    try:
        # List objects with the prefix
        prefix = os.path.dirname(base_path)
        base_name = os.path.basename(base_path).split('.')[0]
        
        s3 = boto3.client('s3')
        response = s3.list_objects_v2(Bucket=AWS_S3_BUCKET, Prefix=prefix)
        
        if 'Contents' not in response:
            return None
            
        # Find matching file
        for obj in response['Contents']:
            obj_base = os.path.basename(obj['Key']).split('.')[0]
            if obj_base == base_name:
                return obj['Key']
                
        return None
    except Exception as e:
        logging.error(f"Error finding {description}: {e}")
        return None

def get_latest_system_prompt(agent_name):
    """Get the latest system prompt for an agent."""
    try:
        # Read base system prompt
        base_key = find_file_by_base('_config/systemprompt_base', 'base system prompt')
        base_content = read_file_content(base_key, 'base system prompt')
        
        # Try to read agent-specific system prompt
        agent_key = find_file_by_base(
            f'organizations/river/agents/{agent_name}/_config/systemprompt_aID-{agent_name}',
            'agent system prompt'
        )
        agent_content = read_file_content(agent_key, 'agent system prompt')
        
        if base_content:
            return agent_content + "\n\n" + base_content if agent_content else base_content
        return None
    except Exception as e:
        print(f"Error reading system prompt: {e}")
        return None

def read_frameworks(agent_name):
    """Read frameworks for an agent."""
    try:
        # Read base frameworks
        base_key = find_file_by_base('_config/frameworks_base', 'base frameworks')
        base_content = read_file_content(base_key, 'base frameworks')
        
        # Try to read agent-specific frameworks
        agent_key = find_file_by_base(
            f'organizations/river/agents/{agent_name}/_config/frameworks_aID-{agent_name}',
            'agent frameworks'
        )
        agent_content = read_file_content(agent_key, 'agent frameworks')
        
        if base_content:
            return agent_content + "\n\n" + base_content if agent_content else base_content
        return None
    except Exception as e:
        print(f"Error reading frameworks: {e}")
        return None

def read_organization_context(agent_name):
    """Read organization context."""
    try:
        context_key = find_file_by_base(f'organizations/river/_config/context_oID-{agent_name}', 'organization context')
        return read_file_content(context_key, 'organization context')
    except Exception as e:
        print(f"Error reading organization context: {e}")
        return None

def read_agent_docs(agent_name):
    """Read agent documentation."""
    try:
        s3 = boto3.client('s3')
        prefix = f'organizations/river/agents/{agent_name}/docs/'
        
        response = s3.list_objects_v2(
            Bucket=AWS_S3_BUCKET,
            Prefix=prefix
        )
        
        if 'Contents' not in response:
            return None
            
        docs = []
        for obj in response['Contents']:
            content = read_file_content(obj['Key'], 'agent documentation')
            if content:
                docs.append(content)
                    
        return "\n\n".join(docs) if docs else None
    except Exception as e:
        print(f"Error reading agent docs: {e}")
        return None

def list_context_files(prefix):
    """List context files in a prefix."""
    try:
        s3 = boto3.client('s3')
        response = s3.list_objects_v2(Bucket=AWS_S3_BUCKET, Prefix=prefix)
        if 'Contents' not in response:
            return []
            
        context_files = []
        for obj in response['Contents']:
            context_files.append(obj['Key'])
        return context_files
    except Exception as e:
        logging.error(f"Error listing context files: {e}")
        return []

```

File: /Users/neonvoid/Library/Mobile Documents/com~apple~CloudDocs/Documents/Projekt/River/River Resources/Code/magic_chat-local/web/web_chat.py
```py
from flask import Flask, request, jsonify, render_template, current_app, Response
from typing import Optional
from utils.transcript_utils import TranscriptState, get_latest_transcript_file, read_new_transcript_content
import threading
from config import AppConfig
import os
import boto3
import logging
from datetime import datetime
import json
import time

def read_file_content(s3_key, file_name):
    try:
        s3 = boto3.client('s3')
        bucket = 'aiademomagicaudio'
        obj = s3.get_object(Bucket=bucket, Key=s3_key)
        return obj['Body'].read().decode('utf-8')
    except Exception as e:
        logging.error(f"Error reading {file_name} from S3: {e}")
        return ""

def find_file_by_base(base_key, file_name):
    try:
        s3 = boto3.client('s3')
        bucket = 'aiademomagicaudio'
        response = s3.list_objects_v2(Bucket=bucket, Prefix=base_key)
        if 'Contents' in response:
            for obj in response['Contents']:
                if obj['Key'].startswith(base_key) and obj['Key'] != base_key:
                    return obj['Key']
        logging.error(f"Error finding {file_name} in S3: {e}")
        return None
    except Exception as e:
        logging.error(f"Error finding {file_name} in S3: {e}")
        return None

def get_latest_system_prompt(agent_name=None):
    """Get and combine system prompts from S3"""
    try:
        # Get base system prompt
        base_key = find_file_by_base('_config/systemprompt_base', 'base system prompt')
        if not base_key:
            return None
        base_prompt = read_file_content(base_key, "base system prompt")
        
        # Get agent-specific system prompt if agent name is provided
        agent_prompt = ""
        if agent_name:
            agent_key = find_file_by_base(
                f'organizations/river/agents/{agent_name}/_config/systemprompt_aID-{agent_name}',
                'agent system prompt'
            )
            if agent_key:
                agent_prompt = read_file_content(agent_key, "agent system prompt")
        
        # Combine prompts
        system_prompt = base_prompt
        if agent_prompt:
            system_prompt += "\n\n" + agent_prompt
            
        return system_prompt
    except Exception as e:
        logging.error(f"Error getting system prompts: {e}")
        return None

def get_latest_frameworks(agent_name=None):
    """Get and combine frameworks from S3"""
    try:
        # Get base frameworks
        base_key = find_file_by_base('_config/frameworks_base', 'base frameworks')
        if not base_key:
            return None
        base_frameworks = read_file_content(base_key, "base frameworks")
        
        # Get agent-specific frameworks if agent name is provided
        agent_frameworks = ""
        if agent_name:
            agent_key = find_file_by_base(
                f'organizations/river/agents/{agent_name}/_config/frameworks_aID-{agent_name}',
                'agent frameworks'
            )
            if agent_key:
                agent_frameworks = read_file_content(agent_key, "agent frameworks")
        
        # Combine frameworks
        frameworks = base_frameworks
        if agent_frameworks:
            frameworks += "\n\n" + agent_frameworks
            
        return frameworks
    except Exception as e:
        logging.error(f"Error getting frameworks: {e}")
        return None

def get_latest_context(agent_name, event_id=None):
    """Get and combine contexts from S3"""
    try:
        # Get organization-specific context
        org_key = find_file_by_base(
            f'organizations/river/_config/context_oID-{agent_name}',
            'organization context'
        )
        if not org_key:
            return None
        org_context = read_file_content(org_key, "organization context")
        
        # Get event-specific context if event ID is provided
        event_context = ""
        if event_id:
            event_key = find_file_by_base(
                f'organizations/river/agents/{agent_name}/events/{event_id}/_config/context_aID-{agent_name}_eID-{event_id}',
                'event context'
            )
            if event_key:
                event_context = read_file_content(event_key, "event context")
        
        # Combine contexts
        context = org_context
        if event_context:
            context += "\n\n" + event_context
            
        return context
    except Exception as e:
        logging.error(f"Error getting contexts: {e}")
        return None

class WebChat:
    def __init__(self, config: AppConfig):
        self.config = config
        self.app = Flask(__name__)
        self.setup_routes()
        self.chat_history = []
        self.client = None
        self.context = None
        self.frameworks = None
        self.transcript = None
        self.system_prompt = None
        
        # Initialize chat filename with timestamp at session start
        timestamp = datetime.now().strftime('%Y%m%d-T%H%M%S')
        self.current_chat_file = f"chat_D{timestamp}_aID-{config.agent_name}_eID-{config.event_id}.txt"
        self.last_saved_index = 0     # Track messages saved via !save command
        self.last_archive_index = 0   # Track messages auto-archived
        logging.debug(f"Initialized chat filename: {self.current_chat_file}")
        
        self.load_resources()
        
    def load_resources(self):
        """Load context, frameworks, and transcript from S3"""
        # Load and combine system prompts
        system_prompt = get_latest_system_prompt(self.config.agent_name)
        if not system_prompt:
            logging.error("Failed to load system prompt")
            return
            
        # Add frameworks
        frameworks = get_latest_frameworks(self.config.agent_name)
        if frameworks:
            system_prompt += "\n\n## Frameworks\n" + frameworks
            
        # Add context
        context = get_latest_context(self.config.agent_name)  # Note: event_id not implemented yet
        if context:
            system_prompt += "\n\n## Context\n" + context
        
        # Store the system prompt
        self.system_prompt = system_prompt
        
        # Load memory if enabled
        if self.config.memory is not None:
            self.system_prompt = self.reload_memory()
            if not self.system_prompt:  # If reload_memory fails, revert to original system prompt
                self.system_prompt = system_prompt

        # Load transcript if listening is enabled
        if self.config.listen_transcript:
            self.load_transcript()

    def reload_memory(self):
        """Reload memory from chat history files"""
        # Import the necessary functions
        from magic_chat import load_existing_chats_from_s3, summarize_text
        
        # Make sure we have a valid system prompt
        if not self.system_prompt:
            logging.error("Cannot reload memory: system prompt is not initialized")
            return None
        
        # Load and process chat history
        if not self.config.memory:
            self.config.memory = [self.config.agent_name]
        previous_chats = load_existing_chats_from_s3(self.config.agent_name, self.config.memory)
        
        # Combine all chat content
        all_content = []
        for chat in previous_chats:
            for msg in chat['messages']:
                all_content.append(msg['content'])
        
        combined_content = "\n\n".join(all_content)  # Add extra newline between files
        summarized_content = summarize_text(combined_content, max_length=None)
        
        # Build new system prompt
        if summarized_content:
            new_system_prompt = (
                self.system_prompt + 
                "\n\n## Previous Chat History\nThe following is a summary of previous chat interactions:\n\n" + 
                summarized_content
            )
        else:
            new_system_prompt = self.system_prompt
        
        return new_system_prompt

    def setup_routes(self):
        @self.app.route('/')
        def index():
            return render_template('index.html', agent_name=self.config.agent_name)
            
        @self.app.route('/api/chat', methods=['POST'])
        def chat():
            data = request.json
            if not data or 'message' not in data:
                return jsonify({'error': 'No message provided'}), 400
            # Process the message and get response
            try:
                # Initialize Anthropic client if needed
                if not self.client:
                    from anthropic import Anthropic
                    import os
                    self.client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))

                # Add user message to history with timestamp
                current_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                user_content = f"On {current_timestamp}, user said: {data['message']}"
                self.chat_history.append({
                    'user': user_content,
                    'assistant': None,
                    'timestamp': current_timestamp
                })
                logging.debug(f"Added user message to history. Total messages: {len(self.chat_history)}")
                # Build conversation history from previous messages
                messages = []
                for chat in self.chat_history:
                    if chat['user']:  # Only add if user message exists
                        messages.append({"role": "user", "content": chat['user']})
                    if chat['assistant']:  # Only add if assistant message exists
                        messages.append({"role": "assistant", "content": chat['assistant']})
                def generate():
                    full_response = ""
                    with self.client.messages.stream(
                        model="claude-3-5-sonnet-20241022",
                        max_tokens=1024,
                        system=self.system_prompt,
                        messages=messages
                    ) as stream:
                        for text in stream.text_stream:
                            full_response += text
                            yield f"data: {json.dumps({'delta': text})}\n\n"
                    # Update the last message with assistant's response
                    if self.chat_history:
                        self.chat_history[-1]['assistant'] = full_response
                    # Save to archive
                    new_messages = self.chat_history[self.last_archive_index:]
                    if new_messages:
                        chat_content = ""
                        for chat in new_messages:
                            if chat.get('user'):
                                chat_content += f"**User:**\n{chat['user']}\n\n"
                            if chat.get('assistant'):
                                chat_content += f"**Agent:**\n{chat['assistant']}\n\n"
                        from magic_chat import save_chat_to_s3
                        success, _ = save_chat_to_s3(
                            agent_name=self.config.agent_name,
                            chat_content=chat_content,
                            event_id=self.config.event_id,
                            is_saved=False,
                            filename=self.current_chat_file
                        )
                        if success:
                            self.last_archive_index = len(self.chat_history)
                        else:
                            logging.error("Failed to save chat history")
                    yield f"data: {json.dumps({'done': True})}\n\n"
                return Response(generate(), mimetype='text/event-stream')
            except Exception as e:
                logging.error(f"Error in chat endpoint: {e}")
                return jsonify({'error': str(e)}), 500
            
        @self.app.route('/api/status', methods=['GET'])
        def status():
            return jsonify({
                'agent_name': self.config.agent_name,
                'listen_summary': self.config.listen_summary,
                'listen_transcript': self.config.listen_transcript,
                'listen_insights': self.config.listen_insights,
                'memory_enabled': self.config.memory is not None
            })
            
        @self.app.route('/api/command', methods=['POST'])
        def command():
            data = request.json
            if not data or 'command' not in data:
                return jsonify({'error': 'No command provided'}), 400
                
            cmd = data['command'].lower()
            if cmd == 'help':
                help_text = (
                    "Available commands:\n"
                    "!help          - Display this help message\n"
                    "!clear         - Clear the chat history\n"
                    "!save          - Save current chat history to S3 saved folder\n"
                    "!memory        - Toggle memory mode (load chat history)\n"
                    "!listen        - Enable summary listening\n"
                    "!listen-all    - Enable all listening modes\n"
                    "!listen-deep   - Enable summary and insights listening\n"
                    "!listen-insights - Enable insights listening\n"
                    "!listen-transcript - Enable transcript listening"
                )
                return jsonify({'message': help_text})
            elif cmd == 'clear':
                self.chat_history = []
                self.last_saved_index = 0
                return jsonify({'message': 'Chat history cleared'})
            elif cmd == 'save':
                try:
                    # Get new messages since last save
                    new_messages = self.chat_history[self.last_saved_index:]
                    logging.debug(f"Messages to save: {len(new_messages)} (total: {len(self.chat_history)}, last saved: {self.last_saved_index})")
                    
                    if not new_messages:
                        return jsonify({'message': 'No new messages to save'})
                    
                    chat_content = ""
                    for chat in new_messages:
                        timestamp = chat.get('timestamp', '')
                        chat_content += f"**User ({timestamp}):**\n{chat['user']}\n\n"
                        if chat['assistant']:
                            chat_content += f"**Agent:**\n{chat['assistant']}\n\n"
                    
                    # Import the save function from magic_chat
                    from magic_chat import save_chat_to_s3
                    
                    success, filename = save_chat_to_s3(
                        agent_name=self.config.agent_name,
                        chat_content=chat_content,
                        event_id=self.config.event_id,
                        is_saved=True,
                        filename=self.current_chat_file
                    )
                    
                    if success:
                        self.last_saved_index = len(self.chat_history)  # Update save index only
                        return jsonify({'message': f'Chat history saved successfully as {filename}'})
                    else:
                        return jsonify({'error': 'Failed to save chat history'})
                except Exception as e:
                    logging.error(f"Error saving chat history: {e}")
                    return jsonify({'error': f'Error saving chat history: {str(e)}'})
            elif cmd == 'memory':
                if self.config.memory is None:
                    self.config.memory = [self.config.agent_name]
                    self.system_prompt = self.reload_memory()
                    if not self.system_prompt:  # If reload_memory fails, revert to original system prompt
                        self.system_prompt = system_prompt
                    return jsonify({'message': 'Memory mode activated'})
                else:
                    self.config.memory = None
                    return jsonify({'message': 'Memory mode deactivated'})
            elif cmd == 'listen':
                self.config.listen_summary = True
                if self.load_transcript():
                    return jsonify({'message': 'Listening to summaries activated and transcript loaded'})
                else:
                    return jsonify({'message': 'Listening to summaries activated (no transcript found)'})
            elif cmd == 'listen-transcript':
                self.config.listen_transcript = True
                if self.load_transcript():
                    return jsonify({'message': 'Transcript loaded and listening mode activated'})
                else:
                    return jsonify({'message': 'No transcript files found'})
            elif cmd == 'listen-insights':
                self.config.listen_insights = True
                return jsonify({'message': 'Listening to insights activated'})
            elif cmd == 'listen-all':
                self.config.listen_summary = True
                self.config.listen_transcript = True
                self.config.listen_insights = True
                self.config.listen_all = True
                if self.load_transcript():
                    return jsonify({'message': 'All listening modes activated and transcript loaded'})
                else:
                    return jsonify({'message': 'All listening modes activated (no transcript found)'})
            elif cmd == 'listen-deep':
                self.config.listen_summary = True
                self.config.listen_insights = True
                self.config.listen_deep = True
                return jsonify({'message': 'Deep listening mode activated'})
            else:
                return jsonify({'error': 'Unknown command'}), 400
            
        @self.app.route('/api/save', methods=['POST'])
        def save_chat():
            """Copy current chat file from archive to saved folder"""
            try:
                if not self.current_chat_file:
                    return jsonify({'error': 'No chat file exists to save'}), 404
                
                # Import the save function from magic_chat
                from magic_chat import save_chat_to_s3
                
                # Copy the current chat file from archive to saved
                success, filename = save_chat_to_s3(
                    agent_name=self.config.agent_name,
                    chat_content="",  # Empty content since we're just copying
                    event_id=self.config.event_id,
                    is_saved=True,
                    filename=self.current_chat_file
                )
                if success:
                    return jsonify({'message': 'Chat history saved successfully'}), 200
                else:
                    return jsonify({'error': 'Failed to save chat history'}), 500
            except Exception as e:
                logging.error(f"Error saving chat history: {e}")
                return jsonify({'error': f'Error saving chat history: {str(e)}'}), 500

    def load_transcript(self):
        """Load latest transcript from agent's transcript directory"""
        try:
            # Import the transcript loading function from magic_chat
            from magic_chat import get_latest_transcript_file
            
            transcript_key = get_latest_transcript_file(self.config.agent_name)
            if transcript_key:
                logging.debug(f"Found transcript file: {transcript_key}")
                s3 = boto3.client('s3')
                transcript_obj = s3.get_object(Bucket=self.config.aws_s3_bucket, Key=transcript_key)
                transcript = transcript_obj['Body'].read().decode('utf-8')
                if transcript:
                    logging.debug(f"Loaded transcript, length: {len(transcript)}")
                    self.transcript = transcript
                    self.system_prompt += f"\n\nTranscript update: {transcript}"
                    logging.debug(f"Updated system prompt, new length: {len(self.system_prompt)}")
                    return True
            
            return False
            
        except Exception as e:
            logging.error(f"Error loading transcript from S3: {e}")
            return False

    def check_transcript_updates(self):
        """Check for new transcript updates"""
        logging.debug("Checking for transcript updates...")
        
        try:
            # First check if we actually have the state and config we need
            if not hasattr(self, 'transcript_state') or not self.transcript_state:
                self.transcript_state = TranscriptState()
                
            new_content = read_new_transcript_content(
                self.transcript_state,
                self.config.agent_name,
                self.config.event_id
            )
            
            if new_content:
                self.chat_history.append({
                    'user': f"[Transcript update - DO NOT SUMMARIZE, just acknowledge receipt]: {new_content}",
                    'assistant': None
                })
                return True
                    
            return False
            
        except Exception as e:
            logging.error(f"Error checking transcript updates: {e}")
            return False

    def run(self, host: str = '127.0.0.1', port: int = 5001, debug: bool = False):
        def check_updates():
            while True:
                if self.config.listen_transcript:
                    self.check_transcript_updates()
                time.sleep(5)  # Same 5-second interval as CLI

        if self.config.listen_transcript:
            from magic_chat import TranscriptState
            self.transcript_state = TranscriptState()
            threading.Thread(target=check_updates, daemon=True).start()

        if self.config.interface_mode == 'web_only':
            self.app.run(host=host, port=port, debug=debug)
        else:
            thread = threading.Thread(
                target=lambda: self.app.run(host=host, port=port, debug=debug, use_reloader=False),
                daemon=True
            )
            thread.start()
            return thread
```

File: /Users/neonvoid/Library/Mobile Documents/com~apple~CloudDocs/Documents/Projekt/River/River Resources/Code/magic_chat-local/web/static/gradient_themes.css
```css
/* Base gradient theme variables */
:root {
    --gradient-color-1: rgba(105, 219, 234, 0.5);
    --gradient-color-2: rgba(52, 224, 204, 0.5);
    --gradient-color-3: rgba(47, 255, 147, 0.5);
    --gradient-color-4: rgba(13, 210, 82, 0.5);
    --base-bg: #000000;
}

/* Background toggle classes */
.bg-wrapper {
    position: relative;
    overflow: hidden;
}

.use-image-bg {
    background-image: url('../static/images/river_bg01.jpg');
    background-size: 100% 100%;
    background-position: center;
    background-repeat: no-repeat;
}

/* Preset themes that can be triggered by keywords */
.theme-calm {
    --gradient-color-1: rgba(44, 62, 80, 0.5);
    --gradient-color-2: rgba(52, 152, 219, 0.5);
    --gradient-color-3: rgba(41, 128, 185, 0.5);
    --gradient-color-4: rgba(52, 73, 94, 0.5);
}

.theme-energetic {
    --gradient-color-1: rgba(192, 57, 43, 0.5);
    --gradient-color-2: rgba(231, 76, 60, 0.5);
    --gradient-color-3: rgba(211, 84, 0, 0.5);
    --gradient-color-4: rgba(230, 126, 34, 0.5);
}

.theme-peaceful {
    --gradient-color-1: rgba(39, 174, 96, 0.5);
    --gradient-color-2: rgba(46, 204, 113, 0.5);
    --gradient-color-3: rgba(22, 160, 133, 0.5);
    --gradient-color-4: rgba(26, 188, 156, 0.5);
}

.theme-mysterious {
    --gradient-color-1: rgba(142, 68, 173, 0.5);
    --gradient-color-2: rgba(155, 89, 182, 0.5);
    --gradient-color-3: rgba(108, 52, 131, 0.5);
    --gradient-color-4: rgba(155, 89, 182, 0.5);
}

/* Animation keyframes for multiple flows */
@keyframes flow1 {
    0% { transform: translate(0, 0); }
    50% { transform: translate(-25%, 20%); }
    100% { transform: translate(0, 0); }
}

@keyframes flow2 {
    0% { transform: translate(0, 0); }
    50% { transform: translate(25%, -20%); }
    100% { transform: translate(0, 0); }
}

@keyframes flow3 {
    0% { transform: translate(0, 0); }
    50% { transform: translate(-15%, -25%); }
    100% { transform: translate(0, 0); }
}

/* Gradient background styles */
.gradient-background {
    position: relative;
    overflow: hidden;
    background-color: var(--base-bg);  /* Base color that affects gradient appearance */
    background-image: linear-gradient(
        135deg,
        var(--gradient-color-1),
        var(--gradient-color-2),
        var(--gradient-color-3),
        var(--gradient-color-4)
    );
}

.gradient-background::before,
.gradient-background::after {
    content: '';
    position: absolute;
    top: -50%;
    left: -50%;
    width: 200%;
    height: 200%;
    opacity: 0.15;
    filter: blur(150px);
    background-size: 400% 400%;
}

.gradient-background::before {
    background: radial-gradient(
        circle at center,
        var(--gradient-color-1) 0%,
        transparent 80%
    ), radial-gradient(
        circle at 60% 40%,
        var(--gradient-color-2) 0%,
        transparent 80%
    );
    animation: flow1 20s ease-in-out infinite;
    mix-blend-mode: plus-lighter;
}

.gradient-background::after {
    background: radial-gradient(
        circle at 40% 60%,
        var(--gradient-color-3) 0%,
        transparent 80%
    ), radial-gradient(
        circle at 50% 50%,
        var(--gradient-color-4) 0%,
        transparent 80%
    );
    animation: flow2 25s ease-in-out infinite;
    mix-blend-mode: plus-lighter;
}
```

File: /Users/neonvoid/Library/Mobile Documents/com~apple~CloudDocs/Documents/Projekt/River/River Resources/Code/magic_chat-local/web/templates/index.html
```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../static/gradient_themes.css">
    <title>Magic Chat - {{ agent_name }}</title>
    <style>
        :root {
            --bg-color: #1a1a1a;
            --base-bg: #0a0a0a;  /* Dark mode/evening default */
            /* --chat-bg: rgb(20, 20, 20, 1.0); */
            --chat-bg: rgb(20, 20, 20, 0.5);
            --text-color: #f0f0f0;
            --input-bg: transparent;
            --input-field-bg: rgba(0, 0, 0, 0.5);
            --accent-color: #d9d9d9;
            --accent-color-hover: #ffffff;
            --action-color: #777777;
            --action-color-hover: #e0e0e0;
            --trigger-color: #a7a7a7;
            --trigger-color-hover: #a7a7a7;
            /* --message-user-bg: #292929; */
            --message-user-bg: rgba(0, 0, 0, 0.5);
            --message-assistant-bg: transparent;
            /* --message-system-bg: #4a4a4a; */
            --message-system-bg: #898989;
            --status-bar: #898989;
        }

        @font-face {
            font-family: 'Avenir Next', 'SF Pro Display', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            src: url('path-to-avenir-next-font.woff2') format('woff2');
            font-weight: 100;
            font-style: normal;
        }

        body {
            font-family: 'Avenir Next', 'SF Pro Display', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            font-weight: 100;
            margin: 0;
            padding: 0;
            color: var(--text-color);
            font-size: 20px;
            line-height: 1.5;
            overflow: hidden;
            height: 100vh;
            position: relative;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        #bg-wrapper {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: -1;
            /* background-image: url('../static/images/river_bg01.jpg'); */
            /* background-size: 100% 100%; */
            /* background-position: center; */
            /* background-repeat: no-repeat; */
        }

        /* Adjust container transparency based on background type */
        .use-image-bg ~ #chat-container {
            background: rgba(71, 71, 71, 0.98);  /* Less transparent when image background is used */
        }
        
        .gradient-background ~ #chat-container {
            background: var(--chat-bg);  /* Default transparency for gradient background */
        }

        #chat-container {
            background: var(--chat-bg);
            border-radius: 25px;
            box-shadow: 0;
            padding: 35px 40px 17px 40px;
            width: calc(95% - 80px);
            max-width: calc(1000px - 40px);
            height: 87vh;
            display: flex;
            flex-direction: column;
            overflow-x: hidden;
        }

        h2 {
            text-align: center;
            margin: 0 0 10px 0;     /* top right bottom left */
            font-size: 20px;
            color: var(--message-system-bg);
            font-weight: 100;
        }

        #chat-messages {
            flex-grow: 1;
            overflow-y: auto;
            overflow-x: hidden;
            margin-bottom: 20px;
            padding: 20px 10px 20px 10px;
            border-radius: 25px;
            background: var(--input-bg);
            width: calc(100% - 20px);
            display: flex;
            flex-direction: column;
            position: relative;
        }

        #chat-messages.thinking {
            display: none;
        }

        #chat-messages.thinking-end {
            display: none;
        }

        @keyframes gradientFlow {
            0% {
                background-position: 0% 50%;
            }
            50% {
                background-position: 100% 50%;
            }
            100% {
                background-position: 0% 50%;
            }
        }

        @keyframes fadeInGlow {
            from { border-color: transparent; }
            to { border-color: rgba(66, 220, 219, 0.5); }
        }

        @keyframes fadeOutGlow {
            from { border-color: rgba(66, 220, 219, 0.5); }
            to { border-color: transparent; }
        }

        @keyframes neonGlow {
            0%, 100% { border-color: rgba(146, 53, 189, 0.75); }
            12% { border-color: rgba(254, 68, 154, 0.75); }
            25% { border-color: rgba(255, 126, 100, 0.75); }
            37% { border-color: rgba(236, 194, 24, 0.75); }
            50% { border-color: rgba(140, 255, 118, 0.75); }
            62% { border-color: rgba(0, 131, 226, 0.75); }
            75% { border-color: rgba(0, 170, 255, 0.75); }
            87% { border-color: rgba(74, 86, 255, 0.75); }
        }

        @keyframes letterGlow {
            0% { 
                opacity: 0;
                color: rgba(146, 53, 189, 1);
            }
            15% { 
                opacity: 1;
                color: rgba(254, 68, 154, 1);
            }
            30% { color: rgba(255, 126, 100, 1); }
            45% { color: rgba(236, 194, 24, 1); }
            60% { color: rgba(140, 255, 118, 1); }
            75% { color: rgba(0, 131, 226, 1); }
            90% { 
                color: rgba(74, 86, 255, 1);
            }
            100% { 
                opacity: 1;
                color: rgba(255, 255, 255, 0.7);
            }
        }

        @keyframes firstRevealGlow {
            0% { 
                opacity: 0;
                color: rgba(146, 53, 189, 1);
            }
            15% { 
                opacity: 1;
                color: rgba(254, 68, 154, 1);
            }
            30% { color: rgba(255, 126, 100, 1); }
            45% { color: rgba(236, 194, 24, 1); }
            60% { color: rgba(140, 255, 118, 1); }
            75% { color: rgba(0, 131, 226, 1); }
            90% { 
                color: rgba(74, 86, 255, 1);
                opacity: 1;
            }
            95% { 
                color: rgba(74, 86, 255, 1);
                opacity: 1;
            }
            100% { 
                color: rgba(255, 255, 255, 0.7);
                opacity: 1;
            }
        }

        @keyframes typeAndGlow {
            0% { 
                opacity: 0;
                transform: translateY(10px);
            }
            100% { 
                opacity: 1;
                transform: translateY(0);
            }
        }

        .glow-text {
            white-space: pre;  
            font-weight: 700;
            color: rgba(255, 255, 255, 0.7);
            font-size: 40px;
            opacity: 0;
            display: inline-block;
            margin-right: 0.1em;
        }

        @media (max-width: 600px) {
            .glow-text {
                font-size: 32px;
            }
        }

        #welcome-text {
            position: absolute;
            top: 65%;
            left: 50%;
            transform: translate(-50%, -50%);
            text-align: center;
            width: 100%;
            white-space: pre-wrap;
            pointer-events: none;
        }

        .glow-text.first-reveal {
            animation: firstRevealGlow 1.5s ease-out forwards;
        }

        .glow-text.visible {
            opacity: 1;
        }

        .glow-text.active {
            animation: typeAndGlow 0.3s ease-out forwards;
            opacity: 1;
        }

        #welcome-container {
            height: 100%;
            display: flex;
            justify-content: center;
            align-items: center;
            color: rgba(255, 255, 255, 0.7);
            font-weight: 700;
            letter-spacing: -0.15em;  
        }

        .message {
            margin-bottom: 15px;
            padding: 18px 22px;
            border-radius: 35px;
            font-size: 20px;
            animation: fadeIn 0.5s ease-out;
            white-space: pre-wrap;
        }

        .message.command {
            color: #20B2AA;  /* Light sea green / teal color */
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .user-message {
            background: var(--message-user-bg);
            margin-left: auto;
            padding-left: 25px;
            border-bottom-right-radius: 5px;
            text-align: left;
            max-width: 60%;
            width: fit-content;
            align-self: flex-end;
        }

        .assistant-message {
            background: var(--message-assistant-bg);
            padding-left: 10px;
            border-bottom-left-radius: 5px;
            width: 95%;
            align-self: stretch;
        }

        .system-message {
            background: var(--message-system-bg);
            margin: 15px auto;
            text-align: center;
        }

        #input-container {
            display: flex;
            gap: 10px;
            position: relative;
            padding: 0 10px;
        }

        .action-buttons {
            display: flex;
            flex-direction: column-reverse;
            gap: 8px;
            position: absolute;
            left: 30px;
            bottom: 18px;
            z-index: 1;
        }

        .action-buttons::before {
            content: '';
            position: absolute;
            inset: -10px;
            background: rgba(19, 19, 19, 0.75);  /* Darker, slightly transparent background */
            border-radius: 20px;
            z-index: -1;
            opacity: 0;
            transition: all 0.3s ease;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
            backdrop-filter: blur(8px);
            transform: translateY(-4px) translateX(0);
        }

        .action-buttons:hover::before {
            opacity: 1;
            transform: translateY(-4px) translateX(4px);
        }

        .action-buttons .action-button:not(#menu-trigger) {
            display: none;
            opacity: 0;
            transition: all 0.3s ease;
            transform: translateY(38px) translateX(0);
        }

        .action-buttons:hover .action-button:not(#menu-trigger) {
            display: flex;
            opacity: 1;
            transform: translateY(-4px) translateX(4px);
        }

        .action-buttons:hover #menu-trigger {
            opacity: 0;
            pointer-events: none;
        }

        #menu-trigger {
            display: flex;
            opacity: 1;
            position: absolute;
            bottom: 0;
            left: 0;
            color: var(--trigger-color);
            transition: opacity 0.3s ease;
            width: 37px;
            height: 37px;
            padding: 4px;
        }

        #menu-trigger svg {
            width: 100%;
            height: 100%;
        }

        #menu-trigger:hover {
            color: var(--trigger-color-hover);
        }

        @media (min-width: 601px) {
            .action-buttons {
                left: 32px;
                gap: 8px;
            }
        }

        @media (max-width: 600px) {
            .action-buttons {
                left: 23px;
                gap: 8px;
                bottom: 9px;
            }

            #menu-trigger {
                width: 36px;
                height: 36px;
            }

            #send-button {
                width: 36px;
                height: 36px;
                right: 20px;
                bottom: 9px;
            }
        }

        .action-button {
            background: transparent;
            border: none;
            color: var(--action-color);
            width: 30px;
            height: 30px;
            padding: 4px;
            cursor: pointer;
            display: flex;
            justify-content: center;
            align-items: center;
            transition: color 0.3s ease;
        }

        .action-button:hover {
            color: var(--action-color-hover);
        }

        .action-button svg {
            width: 100%;
            height: 100%;
        }

        #record-button {
            color: var(--action-color);
        }

        #record-button:hover {
            color: var(--action-color-hover);
        }

        #message-input {
            flex-grow: 1;
            padding: 19px 78px 25px 70px;
            border: none;
            border-radius: 35px;
            font-size: 20px;
            background: var(--input-field-bg);
            color: var(--text-color);
            outline: none;
            font-family: 'Avenir Next', 'SF Pro Display', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            font-weight: 100;
            resize: none;
            overflow-y: hidden;
            line-height: 28px;
            height: 72px;
            min-height: 72px;
            max-height: calc(72px + (28px * 4));
            box-sizing: border-box;
            display: block;
            white-space: pre-wrap;
            word-wrap: break-word;
            border: 4px solid transparent;
        }

        @media (max-width: 600px) {
            #message-input {
                padding: 14px 65px 12px 50px;
                line-height: 20px;
                height: 54px;
                min-height: 54px;
                max-height: calc(54px + (20px * 4));
                font-size: 17px;
            }
        }

        #message-input.thinking {
            border-color: rgba(66, 220, 219, 0.5);
            animation: fadeInGlow 0.5s ease-in forwards,
                       neonGlow 3s ease-in-out infinite 0.5s;
        }

        #message-input.thinking-end {
            animation: fadeOutGlow 0.5s ease-out forwards;
        }

        #message-input::placeholder {
            color: #898989
        }

        #send-button {
            position: absolute;
            right: 25px;
            bottom: 15px;
            width: 42px;
            height: 42px;
            border-radius: 50%;
            background: var(--accent-color);
            color: rgb(26, 26, 26);
            border: none;
            cursor: pointer;
            display: flex;
            justify-content: center;
            align-items: center;
            transition: background 0.3s ease;
        }

        @media (max-width: 600px) {
            #send-button {
                width: 36px;
                height: 36px;
                right: 20px;
                bottom: 9px;
            }
        }

        #send-button:hover {
            background: var(--accent-color-hover);
        }

        #send-button svg {
            width: 26px;
            height: 26px;
        }

        @media (max-width: 600px) {
            #send-button svg {
                width: 20px;
                height: 20px;
            }
        }

        #status-bar {
            font-size: 16px;
            color: var(--status-bar);
            margin-top: 14px;
            text-align: center;
        }

        .waiting {
            display: inline-block;
            width: 10px;
            height: 10px;
            background-color: #ffffff;
            border-radius: 50%;
            animation: breathe 2s ease-in-out infinite;
        }

        @keyframes breathe {
            0% { transform: scale(1); }
            50% { transform: scale(1.5); }
            100% { transform: scale(1); }
        }

        @media (max-width: 600px) {
            #chat-container {
                width: 100%;
                height: 100vh;
                padding: 20px 20px 15px 20px;
                border-radius: 0;
            }

            #chat-messages {
                flex: 1;
                width: 100%;
                margin: 0;
                padding: 0;
            }

            h2 {
                margin: 20px 0 30px 0;
                font-size: 17px;
            }

            #input-container {
                margin: 15px 0 30px 0;
            }

            .message {
                font-size: 18px;
            }

            #welcome-text {
                top: 50%;
            }

            #status-bar {
                display: none;
            }
        }
    </style>
</head>
<body>
    <!-- To switch between backgrounds, add/remove classes:
         - For gradient: class="bg-wrapper gradient-background"
         - For image: class="bg-wrapper use-image-bg"
    -->
    <div id="bg-wrapper" class="bg-wrapper use-image-bg"></div>
    <div id="chat-container">
        <h2>River AI Streamer</h2>
        <div id="chat-messages">
            <div id="welcome-container">
                <span id="welcome-text"></span>
            </div>
        </div>
        <div id="input-container">
            <div class="action-buttons">
                <button class="action-button" id="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <line x1="12" y1="5" x2="12" y2="19"></line>
                        <line x1="5" y1="12" x2="19" y2="12"></line>
                    </svg>
                </button>
                <button class="action-button" id="record-button">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <circle cx="12" cy="12" r="10"></circle>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
                <button class="action-button">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
                        <polyline points="14 2 14 8 20 8"></polyline>
                    </svg>
                </button>
                <button class="action-button">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <path d="M21.44 11.05l-9.19 9.19a6 6 0 0 1-8.49-8.49l9.19-9.19a2 2 0 0 1 2.83 2.83l-8.49 8.48"></path>
                    </svg>
                </button>
                <button class="action-button" id="save-button">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path>
                        <polyline points="7 10 12 15 17 10"></polyline>
                        <line x1="12" y1="15" x2="12" y2="3"></line>
                    </svg>
                </button>
            </div>
            <textarea id="message-input" placeholder="Message AI" rows="1"></textarea>
            <button id="send-button" onclick="sendMessage()">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3.5" stroke-linecap="round" stroke-linejoin="round">
                    <line x1="12" y1="19" x2="12" y2="5"></line>
                    <polyline points="5 12 12 5 19 12"></polyline>
                </svg>
            </button>
        </div>
        <div id="status-bar"></div>
    </div>

    <script>
        let lastMessage = null;  // Track last message globally

        // Initialize message input and event handlers
        const messageInput = document.getElementById('message-input');
        const isMobile = window.innerWidth <= 600;
        const initialHeight = isMobile ? '54px' : '72px';
        messageInput.style.height = initialHeight;

        messageInput.addEventListener('input', function() {
            this.style.height = initialHeight;
            const lineHeight = isMobile ? 20 : 28;
            const maxHeight = parseInt(initialHeight) + (lineHeight * 4);
            this.style.height = Math.min(this.scrollHeight, maxHeight) + 'px';
        });

        // Handle Enter key and Shift+Enter
        messageInput.addEventListener('keypress', function(e) {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                sendMessage();
            }
        });

        function updateStatus() {
            fetch('/api/status')
                .then(response => response.json())
                .then(data => {
                    const status = [];
                    if (data.listen_summary) status.push('summary');
                    if (data.listen_transcript) status.push('transcript');
                    if (data.listen_insights) status.push('insights');
                    
                    const statusBar = document.getElementById('status-bar');
                    const statusText = status.length ? 'Listening to: ' + status.join(', ') : 'Not listening';
                    const memoryText = data.memory_enabled ? 'Memory: yes' : 'Memory: no';
                    statusBar.textContent = 'Agent: ' + '{{ agent_name }}' + ' \u00A0 | \u00A0 ' + statusText + ' \u00A0 | \u00A0 ' + memoryText;
                });
        }

        function sendMessage() {
            const message = messageInput.value.trim();
            if (!message) return;
            
            const welcomeText = document.getElementById('welcome-text');
            if (welcomeText) welcomeText.remove();

            // Just clear the input and reset height
            messageInput.value = '';
            messageInput.style.height = initialHeight;
            messageInput.blur();  // Remove focus
            setTimeout(() => messageInput.focus(), 0);  // Re-focus after a tick
            
            // Handle commands
            if (message.startsWith('!')) {
                const command = message.substring(1).toLowerCase();
                appendMessage('user', message, true);
                
                fetch('/api/command', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ command: command })
                })
                .then(response => response.json())
                .then(data => {
                    if (data.message) {
                        appendMessage('assistant', data.message, true);
                    }
                    if (data.error) {
                        appendMessage('assistant', 'Error: ' + data.error, true);
                    }
                    updateStatus();
                })
                .catch(error => {
                    appendMessage('assistant', 'Error executing command: ' + error, true);
                });
                return;
            }

            // Regular message handling
            appendMessage('user', message);
            
            // Create a new EventSource for streaming response
            const response = fetch('/api/chat', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ message })
            });
            
            let assistantMessage = '';
            messageInput.classList.add('thinking');
            const assistantElement = appendMessage('assistant', '<span class="waiting"></span>');
            
            // Set up event stream from response
            const reader = response.then(res => res.body.getReader());
            const decoder = new TextDecoder();
            
            reader.then(reader => {
                function readChunk() {
                    reader.read().then(({done, value}) => {
                        if (done) return;
                        
                        const chunk = decoder.decode(value);
                        const lines = chunk.split('\n');
                        
                        lines.forEach(line => {
                            if (line.startsWith('data: ')) {
                                const data = JSON.parse(line.slice(6));
                                if (data.delta) {
                                    if (assistantMessage === '') {
                                        assistantElement.innerHTML = ''; // Remove "Thinking..." message
                                        messageInput.classList.add('thinking-end');
                                        setTimeout(() => {
                                            messageInput.classList.remove('thinking');
                                            messageInput.classList.remove('thinking-end');
                                        }, 500);
                                    }
                                    assistantMessage += data.delta;
                                    assistantElement.innerHTML += data.delta;
                                    assistantElement.scrollIntoView({ behavior: 'smooth' });
                                }
                            }
                        });
                        
                        readChunk();
                    }).catch(error => {
                        console.error('Stream error:', error);
                        assistantElement.textContent = 'Error: Failed to get response';
                    });
                }
                readChunk();
            });
        }

        function appendMessage(sender, text, isCommand = false) {
            const initialMessage = document.getElementById('initial-message');
            if (initialMessage) {
                initialMessage.remove();
            }
            
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${sender.toLowerCase()}-message`;
            if (isCommand) {
                messageDiv.classList.add('command');
            }
            messageDiv.innerHTML = text;
            const chatMessages = document.getElementById('chat-messages');

            if (!lastMessage) {
                if (sender.toLowerCase() === 'assistant') {
                    const userMessage = chatMessages.firstChild;
                    chatMessages.insertBefore(messageDiv, userMessage ? userMessage.nextSibling : chatMessages.firstChild);
                } else {
                    chatMessages.insertBefore(messageDiv, chatMessages.firstChild);
                }
            } else {
                chatMessages.insertBefore(messageDiv, lastMessage.nextSibling);
            }
            
            lastMessage = messageDiv;
            // Scroll the message into view immediately after adding it
            messageDiv.scrollIntoView({ behavior: 'smooth', block: 'end' });
            return messageDiv;
        }

        // Initialize the welcome text animation
        const welcomeText = "What is alive today?";
        const welcomeContainer = document.getElementById('welcome-text');
        
        function initializeWelcomeText() {
            welcomeContainer.innerHTML = '';
            [...welcomeText].forEach((char, index) => {
                const span = document.createElement('span');
                span.textContent = char;
                span.className = 'glow-text';
                welcomeContainer.appendChild(span);
            });
        }

        function animateWelcomeText() {
            const letters = welcomeContainer.querySelectorAll('.glow-text');
            letters.forEach((letter, index) => {
                setTimeout(() => {
                    letter.classList.add('first-reveal');
                }, index * 100);
            });
        }

        // Initial setup
        initializeWelcomeText();
        animateWelcomeText();

        // Initial status update
        updateStatus();
        // Update status every 5 seconds
        setInterval(updateStatus, 5000);

        document.getElementById('save-button').addEventListener('click', async () => {
            try {
                const response = await fetch('/api/save', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    }
                });
                
                const data = await response.json();
                if (response.ok) {
                    const messageDiv = document.createElement('div');
                    messageDiv.className = 'system-message';
                    messageDiv.textContent = data.message;
                    const chatMessages = document.getElementById('chat-messages');
                    chatMessages.appendChild(messageDiv);
                    chatMessages.scrollTop = chatMessages.scrollHeight;
                    
                    // Remove the message after 4 seconds
                    setTimeout(() => {
                        messageDiv.style.transition = 'opacity 0.5s ease-out';
                        messageDiv.style.opacity = '0';
                        setTimeout(() => messageDiv.remove(), 500);
                    }, 4000);
                } else {
                    throw new Error(data.error || 'Failed to save chat history');
                }
            } catch (error) {
                console.error('Error saving chat history:', error);
                const messageDiv = document.createElement('div');
                messageDiv.className = 'system-message error';
                messageDiv.textContent = `Error saving chat history: ${error.message}`;
                const chatMessages = document.getElementById('chat-messages');
                chatMessages.appendChild(messageDiv);
                chatMessages.scrollTop = chatMessages.scrollHeight;
                
                // Remove error message after 4 seconds
                setTimeout(() => {
                    messageDiv.style.transition = 'opacity 0.5s ease-out';
                    messageDiv.style.opacity = '0';
                    setTimeout(() => messageDiv.remove(), 500);
                }, 4000);
            }
        });
    </script>
</body>
</html>
```

File: /Users/neonvoid/Library/Mobile Documents/com~apple~CloudDocs/Documents/Projekt/River/River Resources/Code/magic_chat-local/web/templates/index_v1.html
```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Magic Chat - {{ agent_name }}</title>
    <style>
        :root {
            --bg-color: #1a1a1a;
            --chat-bg: rgb(20, 20, 20, 1.0);
            --text-color: #f0f0f0;
            --input-bg: transparent;
            --input-field-bg: #292929;
            --accent-color: #e2e2e2;
            --accent-color-hover: #ffffff;
            --action-color: #777777;
            --action-color-hover: #e0e0e0;
            --trigger-color: #a7a7a7;
            --trigger-color-hover: #a7a7a7;
            --message-user-bg: #292929;
            --message-assistant-bg: transparent;
            --message-system-bg: #4a4a4a;
        }

        @font-face {
            font-family: 'Avenir Next', 'SF Pro Display', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            src: url('path-to-avenir-next-font.woff2') format('woff2');
            font-weight: 100;
            font-style: normal;
        }

        body {
            font-family: 'Avenir Next', 'SF Pro Display', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            font-weight: 100;
            margin: 0;
            padding: 0;
            color: var(--text-color);
            font-size: 20px;
            line-height: 1.5;
            overflow: hidden;
            height: 100vh;
            position: relative;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        #bg-wrapper {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: -1;
            background-image: url('../static/images/river_bg01.jpg');
            background-size: 100% 100%;
            background-position: center;
            background-repeat: no-repeat;
        }

        #chat-container {
            background: var(--chat-bg);
            border-radius: 35px;
            box-shadow: 0;
            padding: 20px 40px;
            width: calc(95% - 80px);
            max-width: calc(1000px - 80px);
            height: 87vh;
            display: flex;
            flex-direction: column;
            overflow-x: hidden;
            border: 4px solid transparent;
        }

        #chat-container.thinking {
            border-color: rgba(66, 220, 219, 0.5);
            animation: fadeInGlow 0.5s ease-in forwards,
                       neonGlow 3s ease-in-out infinite 0.5s;
        }

        #chat-container.thinking-end {
            animation: fadeOutGlow 0.5s ease-out forwards;
        }

        h2 {
            text-align: center;
            margin: 0 0 10px 0;     /* top right bottom left */
            font-size: 20px;
            color: var(--message-system-bg);
            font-weight: 100;
        }

        #chat-messages {
            flex-grow: 1;
            overflow-y: auto;
            overflow-x: hidden;
            margin-bottom: 20px;
            padding: 20px 10px 20px 10px;
            border-radius: 35px;
            background: var(--input-bg);
            width: calc(100% - 40px);
            display: flex;
            flex-direction: column;
            position: relative;
        }

        #chat-messages.thinking {
            display: none;
        }

        #chat-messages.thinking-end {
            display: none;
        }

        @keyframes fadeInGlow {
            from { border-color: transparent; }
            to { border-color: rgba(66, 220, 219, 0.5); }
        }

        @keyframes fadeOutGlow {
            from { border-color: rgba(66, 220, 219, 0.5); }
            to { border-color: transparent; }
        }

        @keyframes neonGlow {
            0%, 100% { border-color: rgba(146, 53, 189, 0.75); }
            12% { border-color: rgba(254, 68, 154, 0.75); }
            25% { border-color: rgba(255, 126, 100, 0.75); }
            37% { border-color: rgba(236, 194, 24, 0.75); }
            50% { border-color: rgba(140, 255, 118, 0.75); }
            62% { border-color: rgba(0, 131, 226, 0.75); }
            75% { border-color: rgba(0, 170, 255, 0.75); }
            87% { border-color: rgba(74, 86, 255, 0.75); }
        }

        @keyframes letterGlow {
            0% { 
                opacity: 0;
                color: rgba(146, 53, 189, 1);
            }
            15% { 
                opacity: 1;
                color: rgba(254, 68, 154, 1);
            }
            30% { color: rgba(255, 126, 100, 1); }
            45% { color: rgba(236, 194, 24, 1); }
            60% { color: rgba(140, 255, 118, 1); }
            75% { color: rgba(0, 131, 226, 1); }
            90% { 
                color: rgba(74, 86, 255, 1);
            }
            100% { 
                opacity: 1;
                color: rgba(255, 255, 255, 0.7);
            }
        }

        @keyframes firstRevealGlow {
            0% { 
                opacity: 0;
                color: rgba(146, 53, 189, 1);
            }
            15% { 
                opacity: 1;
                color: rgba(254, 68, 154, 1);
            }
            30% { color: rgba(255, 126, 100, 1); }
            45% { color: rgba(236, 194, 24, 1); }
            60% { color: rgba(140, 255, 118, 1); }
            75% { color: rgba(0, 131, 226, 1); }
            90% { 
                color: rgba(74, 86, 255, 1);
                opacity: 1;
            }
            95% { 
                color: rgba(74, 86, 255, 1);
                opacity: 1;
            }
            100% { 
                color: rgba(255, 255, 255, 0.7);
                opacity: 1;
            }
        }

        @keyframes typeAndGlow {
            0% { 
                opacity: 0;
                transform: translateY(10px);
            }
            100% { 
                opacity: 1;
                transform: translateY(0);
            }
        }

        .glow-text {
            white-space: pre;  
            font-weight: 700;
            color: rgba(255, 255, 255, 0.7);
            font-size: 40px;
            opacity: 0;
            display: inline-block;
            margin-right: 0.1em;
        }

        @media (max-width: 600px) {
            .glow-text {
                font-size: 29px;
            }
        }

        #welcome-text {
            position: absolute;
            top: 65%;
            left: 53%;
            transform: translate(-50%, -50%);
            text-align: center;
            width: 100%;
            white-space: pre-wrap;
            pointer-events: none;
        }

        .glow-text.first-reveal {
            animation: firstRevealGlow 1.5s ease-out forwards;
        }

        .glow-text.visible {
            opacity: 1;
        }

        .glow-text.active {
            animation: typeAndGlow 0.3s ease-out forwards;
            opacity: 1;
        }

        #welcome-container {
            height: 100%;
            display: flex;
            justify-content: center;
            align-items: center;
            color: rgba(255, 255, 255, 0.7);
            font-weight: 700;
            letter-spacing: -0.15em;  
        }

        .message {
            margin-bottom: 15px;
            padding: 18px 22px;
            border-radius: 35px;
            font-size: 20px;
            animation: fadeIn 0.5s ease-out;
            white-space: pre-wrap;
        }

        .message.command {
            color: #20B2AA;  /* Light sea green / teal color */
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .user-message {
            background: var(--message-user-bg);
            margin-left: auto;
            padding-left: 25px;
            border-bottom-right-radius: 5px;
            text-align: left;
            max-width: 60%;
            width: fit-content;
            align-self: flex-end;
        }

        .assistant-message {
            background: var(--message-assistant-bg);
            padding-left: 10px;
            border-bottom-left-radius: 5px;
            width: 95%;
            align-self: stretch;
        }

        .system-message {
            background: var(--message-system-bg);
            margin: 15px auto;
            text-align: center;
        }

        #input-container {
            display: flex;
            gap: 10px;
            position: relative;
            padding: 0 10px;
        }

        .action-buttons {
            display: flex;
            flex-direction: column-reverse;
            gap: 8px;
            position: absolute;
            left: 30px;
            bottom: 18px;
            z-index: 1;
        }

        .action-buttons::before {
            content: '';
            position: absolute;
            inset: -10px;
            background: rgb(41, 41, 41);
            border-radius: 20px;
            z-index: -1;
            opacity: 0;
            transition: all 0.3s ease;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
            backdrop-filter: blur(8px);
            transform: translateY(-4px) translateX(0);
        }

        .action-buttons:hover::before {
            opacity: 1;
            transform: translateY(-4px) translateX(4px);
        }

        .action-buttons .action-button:not(#menu-trigger) {
            display: none;
            opacity: 0;
            transition: all 0.3s ease;
            transform: translateY(38px) translateX(0);
        }

        .action-buttons:hover .action-button:not(#menu-trigger) {
            display: flex;
            opacity: 1;
            transform: translateY(-4px) translateX(4px);
        }

        .action-buttons:hover #menu-trigger {
            opacity: 0;
            pointer-events: none;
        }

        #menu-trigger {
            display: flex;
            opacity: 1;
            position: absolute;
            bottom: 0;
            left: 0;
            color: var(--trigger-color);
            transition: opacity 0.3s ease;
            width: 37px;
            height: 37px;
            padding: 4px;
        }

        #menu-trigger svg {
            width: 100%;
            height: 100%;
        }

        #menu-trigger:hover {
            color: var(--trigger-color-hover);
        }

        @media (min-width: 601px) {
            .action-buttons {
                left: 32px;
                gap: 8px;
            }
        }

        @media (max-width: 600px) {
            .action-buttons {
                left: 32px;
                gap: 8px;
            }
        }

        .action-button {
            background: transparent;
            border: none;
            color: var(--action-color);
            width: 30px;
            height: 30px;
            padding: 4px;
            cursor: pointer;
            display: flex;
            justify-content: center;
            align-items: center;
            transition: color 0.3s ease;
        }

        .action-button:hover {
            color: var(--action-color-hover);
        }

        .action-button svg {
            width: 100%;
            height: 100%;
        }

        #record-button {
            color: var(--action-color);
        }

        #record-button:hover {
            color: var(--action-color-hover);
        }

        #message-input {
            flex-grow: 1;
            padding: 22px 78px 22px 80px;
            border: none;
            border-radius: 35px;
            font-size: 20px;
            background: var(--input-field-bg);
            color: var(--text-color);
            outline: none;
            font-family: 'Avenir Next', 'SF Pro Display', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            font-weight: 400;
            resize: none;
            overflow-y: hidden;
            line-height: 28px;
            height: 72px;
            min-height: 72px;
            max-height: calc(72px + (28px * 4));
            box-sizing: border-box;
            display: block;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        #message-input::placeholder {
            color: rgba(85, 85, 85, 0.5);
        }

        #send-button {
            position: absolute;
            right: 25px;
            bottom: 15px;
            width: 42px;
            height: 42px;
            border-radius: 50%;
            background: var(--accent-color);
            color: rgb(26, 26, 26);
            border: none;
            cursor: pointer;
            display: flex;
            justify-content: center;
            align-items: center;
            transition: background 0.3s ease;
        }

        #send-button:hover {
            background: var(--accent-color-hover);
        }

        #send-button svg {
            width: 26px;
            height: 26px;
        }

        #status-bar {
            font-size: 16px;
            color: #6a6a6a;
            margin-top: 15px;
            text-align: center;
        }

        .waiting {
            display: inline-block;
            width: 10px;
            height: 10px;
            background-color: #ffffff;
            border-radius: 50%;
            animation: breathe 2s ease-in-out infinite;
        }

        @keyframes breathe {
            0% { transform: scale(1); }
            50% { transform: scale(1.5); }
            100% { transform: scale(1); }
        }

        @media (max-width: 600px) {
            #chat-container {
                width: 95%;
                height: 90vh;
                padding: 20px;
            }

            .message {
                font-size: 18px;
            }

            #message-input {
                font-size: 18px;
            }
        }
    </style>
</head>
<body>
    <div id="bg-wrapper"></div>
    <div id="chat-container">
        <h2>River AI Streamer</h2>
        <div id="chat-messages">
            <div id="welcome-container">
                <span id="welcome-text"></span>
            </div>
        </div>
        <div id="input-container">
            <div class="action-buttons">
                <button class="action-button" id="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <line x1="12" y1="5" x2="12" y2="19"></line>
                        <line x1="5" y1="12" x2="19" y2="12"></line>
                    </svg>
                </button>
                <button class="action-button" id="record-button">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <circle cx="12" cy="12" r="10"></circle>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
                <button class="action-button">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
                        <polyline points="14 2 14 8 20 8"></polyline>
                    </svg>
                </button>
                <button class="action-button">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <path d="M21.44 11.05l-9.19 9.19a6 6 0 0 1-8.49-8.49l9.19-9.19a2 2 0 0 1 2.83 2.83l-8.49 8.48"></path>
                    </svg>
                </button>
                <button class="action-button" id="save-button">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path>
                        <polyline points="7 10 12 15 17 10"></polyline>
                        <line x1="12" y1="15" x2="12" y2="3"></line>
                    </svg>
                </button>
            </div>
            <textarea id="message-input" placeholder="Message AI" rows="1"></textarea>
            <button id="send-button" onclick="sendMessage()">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3.5" stroke-linecap="round" stroke-linejoin="round">
                    <line x1="12" y1="19" x2="12" y2="5"></line>
                    <polyline points="5 12 12 5 19 12"></polyline>
                </svg>
            </button>
        </div>
        <div id="status-bar"></div>
    </div>

    <script>
        let lastMessage = null;  // Track last message globally

        // Initialize message input and event handlers
        const messageInput = document.getElementById('message-input');
        const initialHeight = 72;  // matches CSS height (22px + 24px + 22px)

        // Handle Enter key and Shift+Enter
        messageInput.addEventListener('keypress', function(e) {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                sendMessage();
            }
        });

        // Auto-resize textarea
        messageInput.style.height = initialHeight + 'px';
        messageInput.addEventListener('input', function() {
            this.style.height = initialHeight + 'px';
            this.style.height = Math.min(this.scrollHeight, initialHeight + (28 * 4)) + 'px';
        });

        function updateStatus() {
            fetch('/api/status')
                .then(response => response.json())
                .then(data => {
                    const status = [];
                    if (data.listen_summary) status.push('summary');
                    if (data.listen_transcript) status.push('transcript');
                    if (data.listen_insights) status.push('insights');
                    
                    const statusBar = document.getElementById('status-bar');
                    const statusText = status.length ? 'Listening to: ' + status.join(', ') : 'Not listening';
                    const memoryText = data.memory_enabled ? 'Memory: yes' : 'Memory: no';
                    statusBar.textContent = 'Agent: ' + '{{ agent_name }}' + ' \u00A0 | \u00A0 ' + statusText + ' \u00A0 | \u00A0 ' + memoryText;
                });
        }

        function sendMessage() {
            const message = messageInput.value.trim();
            if (!message) return;
            
            const welcomeText = document.getElementById('welcome-text');
            if (welcomeText) welcomeText.remove();

            // Just clear the input and reset height
            messageInput.value = '';
            messageInput.style.height = '72px';
            messageInput.blur();  // Remove focus
            setTimeout(() => messageInput.focus(), 0);  // Re-focus after a tick
            
            // Handle commands
            if (message.startsWith('!')) {
                const command = message.substring(1).toLowerCase();
                appendMessage('user', message, true);
                
                fetch('/api/command', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ command: command })
                })
                .then(response => response.json())
                .then(data => {
                    if (data.message) {
                        appendMessage('assistant', data.message, true);
                    }
                    if (data.error) {
                        appendMessage('assistant', 'Error: ' + data.error, true);
                    }
                    updateStatus();
                })
                .catch(error => {
                    appendMessage('assistant', 'Error executing command: ' + error, true);
                });
                return;
            }

            // Regular message handling
            appendMessage('user', message);
            
            // Create a new EventSource for streaming response
            const response = fetch('/api/chat', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ message })
            });
            
            let assistantMessage = '';
            document.getElementById('chat-container').classList.add('thinking');
            const assistantElement = appendMessage('assistant', '<span class="waiting"></span>');
            
            // Set up event stream from response
            const reader = response.then(res => res.body.getReader());
            const decoder = new TextDecoder();
            
            reader.then(reader => {
                function readChunk() {
                    reader.read().then(({done, value}) => {
                        if (done) return;
                        
                        const chunk = decoder.decode(value);
                        const lines = chunk.split('\n');
                        
                        lines.forEach(line => {
                            if (line.startsWith('data: ')) {
                                const data = JSON.parse(line.slice(6));
                                if (data.delta) {
                                    if (assistantMessage === '') {
                                        assistantElement.innerHTML = ''; // Remove "Thinking..." message
                                        const chatContainer = document.getElementById('chat-container');
                                        chatContainer.classList.add('thinking-end');
                                        setTimeout(() => {
                                            chatContainer.classList.remove('thinking');
                                            chatContainer.classList.remove('thinking-end');
                                        }, 500);
                                    }
                                    assistantMessage += data.delta;
                                    assistantElement.innerHTML += data.delta;
                                    assistantElement.scrollIntoView({ behavior: 'smooth' });
                                }
                            }
                        });
                        
                        readChunk();
                    }).catch(error => {
                        console.error('Stream error:', error);
                        assistantElement.textContent = 'Error: Failed to get response';
                    });
                }
                readChunk();
            });
        }

        function appendMessage(sender, text, isCommand = false) {
            const initialMessage = document.getElementById('initial-message');
            if (initialMessage) {
                initialMessage.remove();
            }
            
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${sender.toLowerCase()}-message`;
            if (isCommand) {
                messageDiv.classList.add('command');
            }
            messageDiv.innerHTML = text;
            const chatMessages = document.getElementById('chat-messages');

            if (!lastMessage) {
                if (sender.toLowerCase() === 'assistant') {
                    const userMessage = chatMessages.firstChild;
                    chatMessages.insertBefore(messageDiv, userMessage ? userMessage.nextSibling : chatMessages.firstChild);
                } else {
                    chatMessages.insertBefore(messageDiv, chatMessages.firstChild);
                }
            } else {
                chatMessages.insertBefore(messageDiv, lastMessage.nextSibling);
            }
            
            lastMessage = messageDiv;
            // Scroll the message into view immediately after adding it
            messageDiv.scrollIntoView({ behavior: 'smooth', block: 'end' });
            return messageDiv;
        }

        // Initialize the welcome text animation
        const welcomeText = "What is alive today?";
        const welcomeContainer = document.getElementById('welcome-text');
        
        function initializeWelcomeText() {
            welcomeContainer.innerHTML = '';
            [...welcomeText].forEach((char, index) => {
                const span = document.createElement('span');
                span.textContent = char;
                span.className = 'glow-text';
                welcomeContainer.appendChild(span);
            });
        }

        function animateWelcomeText() {
            const letters = welcomeContainer.querySelectorAll('.glow-text');
            letters.forEach((letter, index) => {
                setTimeout(() => {
                    letter.classList.add('first-reveal');
                }, index * 100);
            });
        }

        // Initial setup
        initializeWelcomeText();
        animateWelcomeText();

        // Initial status update
        updateStatus();
        // Update status every 5 seconds
        setInterval(updateStatus, 5000);

        document.getElementById('save-button').addEventListener('click', async () => {
            try {
                const response = await fetch('/api/save', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    }
                });
                
                const data = await response.json();
                if (response.ok) {
                    const messageDiv = document.createElement('div');
                    messageDiv.className = 'system-message';
                    messageDiv.textContent = data.message;
                    const chatMessages = document.getElementById('chat-messages');
                    chatMessages.appendChild(messageDiv);
                    chatMessages.scrollTop = chatMessages.scrollHeight;
                    
                    // Remove the message after 4 seconds
                    setTimeout(() => {
                        messageDiv.style.transition = 'opacity 0.5s ease-out';
                        messageDiv.style.opacity = '0';
                        setTimeout(() => messageDiv.remove(), 500);
                    }, 4000);
                } else {
                    throw new Error(data.error || 'Failed to save chat history');
                }
            } catch (error) {
                console.error('Error saving chat history:', error);
                const messageDiv = document.createElement('div');
                messageDiv.className = 'system-message error';
                messageDiv.textContent = `Error saving chat history: ${error.message}`;
                const chatMessages = document.getElementById('chat-messages');
                chatMessages.appendChild(messageDiv);
                chatMessages.scrollTop = chatMessages.scrollHeight;
                
                // Remove error message after 4 seconds
                setTimeout(() => {
                    messageDiv.style.transition = 'opacity 0.5s ease-out';
                    messageDiv.style.opacity = '0';
                    setTimeout(() => messageDiv.remove(), 500);
                }, 4000);
            }
        });
    </script>
</body>
</html>
```

File: /Users/neonvoid/Library/Mobile Documents/com~apple~CloudDocs/Documents/Projekt/River/River Resources/Code/magic_chat-local/config.py
```py
from dataclasses import dataclass
from typing import List, Dict, Optional
import os
import argparse
from dotenv import load_dotenv

@dataclass
class AppConfig:
    """Configuration class that holds all application settings"""
    # Core settings
    agent_name: str
    interface_mode: str  # 'cli', 'web', or 'web_only'
    web_port: int = 5001  # Default web port
    
    # Optional settings with defaults
    memory: List[str] = None
    debug: bool = False
    
    # Listener settings
    listen_summary: bool = False
    listen_transcript: bool = False
    listen_insights: bool = False
    listen_deep: bool = False
    listen_all: bool = False
    listen_transcript_enabled: bool = False  # Track if transcript listening is currently enabled

    # Environment settings
    aws_region: Optional[str] = None
    aws_s3_bucket: Optional[str] = None
    anthropic_api_key: Optional[str] = None
    openai_api_key: Optional[str] = None
    event_id: str = '0000'  # Default event ID

    @classmethod
    def from_env_and_args(cls) -> 'AppConfig':
        """Create configuration from environment variables and command line arguments"""
        # Load environment variables
        load_dotenv()
        
        # Parse command line arguments
        parser = argparse.ArgumentParser(description="Run a Claude agent instance.")
        parser.add_argument('--agent', required=True, help='Unique name for the agent.')
        parser.add_argument('--memory', nargs='*', help='Names of agents to load chat history from.', default=None)
        parser.add_argument('--debug', action='store_true', help='Enable debug mode.')
        parser.add_argument('--web', action='store_true', help='Run with web interface.')
        parser.add_argument('--web-only', action='store_true', help='Run with web interface only (no CLI fallback).')
        parser.add_argument('--web-port', type=int, default=5001, help='Port for web interface (default: 5001)')
        
        # Listener arguments
        parser.add_argument('--listen', action='store_true', help='Enable summary listening at startup.')
        parser.add_argument('--listen-transcript', action='store_true', help='Enable transcript listening at startup.')
        parser.add_argument('--listen-insights', action='store_true', help='Enable insights listening at startup.')
        parser.add_argument('--listen-deep', action='store_true', help='Enable summary and insights listening at startup.')
        parser.add_argument('--listen-all', action='store_true', help='Enable all listening at startup.')
        parser.add_argument('--event', type=str, default='0000', help='Event ID (default: 0000)')
        
        args = parser.parse_args()
        
        # Determine interface mode
        if args.web_only:
            interface_mode = 'web_only'
        elif args.web:
            interface_mode = 'web'
        else:
            interface_mode = 'cli'

        # Process listener flags
        listen_summary = args.listen or args.listen_deep or args.listen_all
        listen_transcript = args.listen_transcript or args.listen_all
        listen_insights = args.listen_insights or args.listen_deep or args.listen_all
        
        # Create config instance
        config = cls(
            agent_name=args.agent,
            interface_mode=interface_mode,
            web_port=args.web_port,
            event_id=args.event,  # Add event_id from args
            memory=args.memory,
            debug=args.debug,
            listen_summary=listen_summary,
            listen_transcript=listen_transcript,  # Set from command line arg
            listen_insights=listen_insights,
            listen_deep=args.listen_deep,
            listen_all=args.listen_all,
            listen_transcript_enabled=False,  # Always start disabled, enable only when needed
            # Environment variables
            aws_region=os.getenv('AWS_REGION'),
            aws_s3_bucket=os.getenv('AWS_S3_BUCKET'),
            anthropic_api_key=os.getenv('ANTHROPIC_API_KEY'),
            openai_api_key=os.getenv('OPENAI_API_KEY')
        )
        
        # Validate configuration
        config.validate()
        return config
    
    def validate(self) -> None:
        """Validate the configuration"""
        missing_vars = []
        
        # Check required environment variables
        if not self.aws_region:
            missing_vars.append('AWS_REGION')
        if not self.aws_s3_bucket:
            missing_vars.append('AWS_S3_BUCKET')
        if not self.anthropic_api_key:
            missing_vars.append('ANTHROPIC_API_KEY')
        if not self.openai_api_key:
            missing_vars.append('OPENAI_API_KEY')
            
        if missing_vars:
            raise ValueError(f"Missing environment variables: {', '.join(missing_vars)}")
        
        # Validate interface mode
        valid_modes = {'cli', 'web', 'web_only'}
        if self.interface_mode not in valid_modes:
            raise ValueError(f"Invalid interface mode: {self.interface_mode}")
```

File: /Users/neonvoid/Library/Mobile Documents/com~apple~CloudDocs/Documents/Projekt/River/River Resources/Code/magic_chat-local/magic_chat.py
```py
import os
import sys
import logging
import time
import argparse
import select
import threading
from anthropic import Anthropic, AnthropicError
from datetime import datetime
import boto3
import json
from models import InsightsOutput
from dotenv import load_dotenv
from config import AppConfig
from web.web_chat import WebChat
import xml.etree.ElementTree as ET
from io import StringIO
from utils.transcript_utils import TranscriptState, get_latest_transcript_file, read_new_transcript_content

SESSION_START_TAG = '<session>'
SESSION_END_TAG = '</session>'
SESSION_END_MARKER = '\n### Chat Session End ###'

abort_requested = False

TOKEN_LIMIT = 4096
AVERAGE_TOKENS_PER_MESSAGE = 50
MAX_MESSAGES = TOKEN_LIMIT // AVERAGE_TOKENS_PER_MESSAGE

# Global transcript position tracker
LAST_TRANSCRIPT_POS = 0

def check_transcript_updates(transcript_state, conversation_history, agent_name, event_id):
    logging.debug("Checking for transcript updates...")
    new_content = read_new_transcript_content(transcript_state, agent_name, event_id)
    if new_content:
        logging.debug(f"Adding new transcript content: {new_content[:100]}...")
        conversation_history.append({
            "role": "transcript",
            "content": new_content
        })
        return True
    return False

# Load environment variables from .env file
load_dotenv()

# Retrieve AWS configurations from environment variables
AWS_REGION = os.getenv('AWS_REGION')
AWS_S3_BUCKET = os.getenv('AWS_S3_BUCKET')

# Retrieve API keys from environment variables
ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

# Validate required environment variables
missing_vars = []
if not AWS_REGION:
    missing_vars.append('AWS_REGION')
if not AWS_S3_BUCKET:
    missing_vars.append('AWS_S3_BUCKET')
if not ANTHROPIC_API_KEY:
    missing_vars.append('ANTHROPIC_API_KEY')
if not OPENAI_API_KEY:
    missing_vars.append('OPENAI_API_KEY')

if missing_vars:
    logging.error(f"Missing environment variables in .env file: {', '.join(missing_vars)}")
    sys.exit(1)

# Initialize AWS S3 client
s3_client = boto3.client(
    's3',
    region_name=AWS_REGION,
    aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),
    aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY')
)

def parse_arguments():
    parser = argparse.ArgumentParser(description="Run a Claude agent instance.")
    parser.add_argument('--agent', required=True, help='Unique name for the agent.')
    parser.add_argument('--memory', nargs='*', help='Names of agents to load chat history from.', default=None)
    parser.add_argument('--debug', action='store_true', help='Enable debug mode.')
    parser.add_argument('--listen', action='store_true', help='Enable summary listening at startup.')
    parser.add_argument('--listen-transcript', action='store_true', help='Enable transcript listening at startup.')
    parser.add_argument('--listen-insights', action='store_true', help='Enable insights listening at startup.')
    parser.add_argument('--listen-deep', action='store_true', help='Enable summary and insights listening at startup.')
    parser.add_argument('--listen-all', action='store_true', help='Enable all listening at startup.')
    parser.add_argument('--interface-mode', choices=['cli', 'web', 'web_only'], default='cli', help='Interface mode.')
    parser.add_argument('--event', type=str, default='0000', help='Event ID for transcript folder (e.g., "20250116")')
    return parser.parse_args()

def setup_logging(debug):
    log_filename = 'claude_chat.log'
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG if debug else logging.ERROR)

    file_handler = logging.FileHandler(log_filename)
    file_handler.setLevel(logging.DEBUG if debug else logging.ERROR)
    file_formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')
    file_handler.setFormatter(file_formatter)
    logger.addHandler(file_handler)

    if debug:
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.DEBUG)
        console_formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')
        console_handler.setFormatter(console_formatter)
        logger.addHandler(console_handler)
    
    # Disable debug logging for external libraries
    logging.getLogger('anthropic').setLevel(logging.WARNING)
    logging.getLogger('boto3').setLevel(logging.WARNING)
    logging.getLogger('botocore').setLevel(logging.WARNING)
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    logging.getLogger('s3transfer').setLevel(logging.WARNING)

def get_latest_system_prompt(agent_name=None):
    """Get and combine system prompts from S3"""
    try:
        s3_client = boto3.client('s3')
        
        # Get base system prompt
        base_key, base_prompt = find_file_any_extension('_config/systemprompt_base', "base system prompt")
        
        # Get agent-specific system prompt if agent name is provided
        agent_prompt = ""
        if agent_name:
            agent_key, agent_prompt = find_file_any_extension(
                f'organizations/river/agents/{agent_name}/_config/systemprompt_aID-{agent_name}',
                "agent system prompt"
            )
        
        # Combine prompts
        system_prompt = base_prompt
        if agent_prompt:
            system_prompt += "\n\n" + agent_prompt
            
        return system_prompt
    except Exception as e:
        logging.error(f"Error getting system prompts: {e}")
        return None

def get_latest_frameworks(agent_name=None):
    """Get and combine frameworks from S3"""
    try:
        s3_client = boto3.client('s3')
        
        # Get base frameworks
        base_key, base_frameworks = find_file_any_extension('_config/frameworks_base', "base frameworks")
        
        # Get agent-specific frameworks if agent name is provided
        agent_frameworks = ""
        if agent_name:
            agent_key, agent_frameworks = find_file_any_extension(
                f'organizations/river/agents/{agent_name}/_config/frameworks_aID-{agent_name}',
                "agent frameworks"
            )
        
        # Combine frameworks
        frameworks = base_frameworks
        if agent_frameworks:
            frameworks += "\n\n" + agent_frameworks
            
        return frameworks
    except Exception as e:
        logging.error(f"Error getting frameworks: {e}")
        return None

def get_latest_context(agent_name, event_id=None):
    """Get and combine contexts from S3, with optional event_id"""
    try:
        # Get organization-specific context
        org_key, org_context = find_file_any_extension(
            f'organizations/river/_config/context_oID-{agent_name}',
            "organization context"
        )
        
        # Get event-specific context if event ID is provided
        event_context = ""
        if event_id:
            event_key, event_context = find_file_any_extension(
                f'organizations/river/agents/{agent_name}/events/{event_id}/_config/context_aID-{agent_name}_eID-{event_id}',
                "event context"
            )
        
        # Combine contexts
        context = org_context if org_context else ""
        if event_context:
            context += "\n\n" + event_context
        
        return context
    except Exception as e:
        logging.error(f"Error getting contexts: {e}")
        return None

def get_agent_docs(agent_name):
    """Get documentation files for the specified agent."""
    try:
        # List objects in the agent's docs folder
        prefix = f'organizations/river/agents/{agent_name}/docs/'
        logging.debug(f"Searching for agent documentation in '{prefix}'")
        
        response = s3_client.list_objects_v2(Bucket=AWS_S3_BUCKET, Prefix=prefix)
        
        if 'Contents' not in response:
            logging.debug(f"No documentation files found in '{prefix}'")
            return None
            
        # Get all documentation files regardless of extension
        docs = []
        for obj in response['Contents']:
            content = read_file_content(obj['Key'], 'agent documentation')
            if content:
                docs.append(content)
                    
        return "\n\n".join(docs) if docs else None
    except Exception as e:
        logging.error(f"Error getting agent documentation: {e}")
        return None

def find_file_any_extension(base_pattern, description):
    """Find a file matching base pattern with any extension in S3.
    Args:
        base_pattern: Base filename pattern without extension (e.g. 'path/to/file')
        description: Description for logging
    Returns:
        Tuple of (file_key, content) or (None, None) if not found
    """
    try:
        # List objects with the base pattern
        prefix = base_pattern.rsplit('/', 1)[0] + '/'
        logging.debug(f"Searching for {description} with prefix '{prefix}'")
        response = s3_client.list_objects_v2(Bucket=AWS_S3_BUCKET, Prefix=prefix)
        
        if 'Contents' in response:
            base_name = base_pattern.rsplit('/', 1)[1]
            logging.debug(f"Found {len(response['Contents'])} objects in prefix '{prefix}'")
            # Find files matching base pattern regardless of extension
            matching_files = [
                obj['Key'] for obj in response['Contents']
                if obj['Key'].rsplit('.', 1)[0] == base_pattern
            ]
            
            if matching_files:
                logging.debug(f"Found {len(matching_files)} matching files for {description}: {matching_files}")
                # Sort by last modified time to get the most recent
                matching_files.sort(
                    key=lambda k: s3_client.head_object(Bucket=AWS_S3_BUCKET, Key=k)['LastModified'],
                    reverse=True
                )
                content = read_file_content(matching_files[0], description)
                if content:
                    logging.debug(f"Successfully loaded content from {matching_files[0]}, length: {len(content)}")
                return matching_files[0], content
        else:
            logging.debug(f"No objects found in prefix '{prefix}'")
        return None, None
        
    except Exception as e:
        logging.error(f"Error finding {description} file for pattern '{base_pattern}': {e}")
        return None, None

def load_existing_chats_from_s3(agent_name, memory_agents=None):
    """Load chat history from S3 for the specified agent(s)"""
    try:
        chat_histories = []
        agents_to_load = [agent_name] if memory_agents is None else memory_agents

        for agent in agents_to_load:
            # Use default event '0000' since events are not yet implemented
            # Only load from saved directory when memory is enabled
            prefix = f'organizations/river/agents/{agent}/events/0000/chats/saved/'
            
            try:
                response = s3_client.list_objects_v2(Bucket=AWS_S3_BUCKET, Prefix=prefix)
                if 'Contents' in response:
                    # Find all chat files regardless of extension
                    chat_files = [
                        obj for obj in response['Contents'] 
                        if obj['Key'].startswith(prefix + 'chat_')
                    ]
                    
                    for chat_file in chat_files:
                        try:
                            chat_content = read_file_content(chat_file['Key'], f"chat file {chat_file['Key']}")
                            if not chat_content:
                                continue
                                
                            # Parse chat content into messages
                            messages = []
                            current_role = None
                            current_content = []
                            
                            for line in chat_content.split('\n'):
                                if line.startswith('**User:**'):
                                    if current_role and current_content:
                                        messages.append({
                                            'role': current_role,
                                            'content': '\n'.join(current_content).strip()
                                        })
                                    current_role = 'user'
                                    current_content = []
                                elif line.startswith('**Agent:**'):
                                    if current_role and current_content:
                                        messages.append({
                                            'role': current_role,
                                            'content': '\n'.join(current_content).strip()
                                        })
                                    current_role = 'assistant'
                                    current_content = []
                                elif line.strip():
                                    current_content.append(line.strip())
                            
                            # Add the last message if exists
                            if current_role and current_content:
                                messages.append({
                                    'role': current_role,
                                    'content': '\n'.join(current_content).strip()
                                })
                            
                            if messages:  # Only add if there are valid messages
                                chat_histories.append({
                                    'agent': agent,
                                    'file': chat_file['Key'],
                                    'messages': messages
                                })
                            
                        except Exception as e:
                            logging.error(f"Error reading chat file {chat_file['Key']}: {e}")
                            continue
                    
            except Exception as e:
                logging.error(f"Error listing chat files for agent {agent}: {e}")
                continue
                
        return chat_histories
        
    except Exception as e:
        logging.error(f"Error loading chat histories from S3: {e}")
        return []

def parse_xml_content(xml_string):
    """Parse XML content and return a formatted string"""
    try:
        # Parse XML
        root = ET.fromstring(xml_string)
        logging.debug(f"XML root element: <{root.tag}>")
        
        # Extract text content recursively
        def extract_text(element, depth=0):
            result = []
            # Add element name as section header if it's not a technical element
            if not element.tag.startswith('{'):
                header = '#' * (depth + 1) + ' ' + element.tag.capitalize()
                result.append(header)
                if depth == 0:  # Log top-level sections
                    logging.debug(f"Processing XML section: {header}")
            
            # Add element text if it exists and is not just whitespace
            if element.text and element.text.strip():
                result.append(element.text.strip())
            
            # Process child elements
            for child in element:
                result.extend(extract_text(child, depth + 1))
                # Add tail text if it exists and is not just whitespace
                if child.tail and child.tail.strip():
                    result.append(child.tail.strip())
            
            return result
        
        # Convert to formatted string
        content = '\n\n'.join(extract_text(root))
        preview = content[:100].replace('\n', '\\n')
        logging.debug(f"XML parsed successfully. Preview of formatted content: {preview}...")
        return content
    except ET.ParseError as e:
        logging.warning(f"Failed to parse XML content, returning raw text: {e}")
        return xml_string

def read_file_content(file_key, description):
    """Read content from S3 file"""
    try:
        # Verify S3 key exists before reading
        try:
            s3_client.head_object(Bucket=AWS_S3_BUCKET, Key=file_key)
        except s3_client.exceptions.ClientError as e:
            if e.response['Error']['Code'] == '404':
                logging.warning(f"S3 key not found: {file_key}")
                return None
            else:
                raise

        logging.debug(f"Reading {description} from S3: {file_key}")
        response = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=file_key)
        content = response['Body'].read().decode('utf-8')
        
        if content:
            logging.debug(f"Successfully read {description} ({len(content)} chars)")
            return content
        else:
            logging.warning(f"Empty content for {description}")
            return None
            
    except Exception as e:
        logging.error(f"Error reading {description} from S3: {e}")
        return None

def summarize_text(text, max_length=None):
    if max_length is None or len(text) <= max_length:
        return text
    else:
        return text[:max_length] + "..."

def analyze_with_claude(client, messages, system_prompt):
    """Process messages with Claude API, handling transcript updates appropriately"""
    logging.debug(f"\n=== Claude API Request ===")
    logging.debug(f"System prompt length: {len(system_prompt)} chars")
    
    # Format messages for Claude API - handle transcript updates and maintain system messages
    formatted_messages = []
    for msg in messages:
        if msg["role"] == "transcript":
            # Convert transcript updates to user messages for API call
            formatted_messages.append({
                "role": "user",
                "content": f"[Transcript update - DO NOT SUMMARIZE, just acknowledge receipt]: {msg['content']}"
            })
        elif msg["role"] == "system":
            # Keep system messages as is
            formatted_messages.append(msg)
        else:
            # Include all other messages with their original roles
            formatted_messages.append({
                "role": "assistant" if msg["role"] == "assistant" else "user",
                "content": msg["content"]
            })

    logging.debug(f"Number of messages: {len(formatted_messages)}")
    logging.debug("Message sizes:")
    for i, msg in enumerate(formatted_messages):
        logging.debug(f"  Message {i}: {len(msg['content'])} chars ({msg['role']})")
    
    try:
        response = client.messages.create(
            model="claude-3-opus-20240229",
            system=system_prompt + "\nIMPORTANT: When you receive transcript updates, do not summarize them. Simply acknowledge that you've received the update and continue the conversation.",  # Add instruction to not summarize
            messages=formatted_messages,  # Context/docs/memory in messages array
            max_tokens=4096
        )
        logging.debug("\n=== Claude API Response ===")
        logging.debug(f"Response length: {len(response.content[0].text)} chars")
        return response.content[0].text
    except Exception as e:
        logging.error(f"Error calling Claude API: {str(e)}")
        return f"Error: {str(e)}"

def save_chat_to_s3(agent_name, chat_content, event_id, is_saved=False, filename=None):
    """Save chat content to S3 bucket or copy from archive to saved.
    
    Args:
        agent_name: Name of the agent
        chat_content: Content to append to chat file
        event_id: Event ID for folder path (defaults to 0000)
        is_saved: Whether this is a manual save (True) or auto-archive (False)
        filename: Optional filename to use, if None one will be generated
        
    Returns:
        Tuple of (success boolean, filename used)
    """
    if event_id is None:
        event_id = '0000'  # Default event ID if none provided

    try:
        if not filename:
            # Generate filename if not provided
            timestamp = datetime.now().strftime('%Y%m%d-T%H%M%S')
            filename = f"chat_D{timestamp}_aID-{agent_name}_eID-{event_id}.txt"
            logging.debug(f"Generated new filename: {filename}")
        
        # Base path for both archive and saved folders
        base_path = f"organizations/river/agents/{agent_name}/events/{event_id}/chats"
        archive_key = f"{base_path}/archive/{filename}"
        saved_key = f"{base_path}/saved/{filename}"
        
        if is_saved:
            try:
                # Copy from archive to saved
                copy_source = {
                    'Bucket': AWS_S3_BUCKET,
                    'Key': archive_key
                }
                s3_client.copy_object(
                    CopySource=copy_source,
                    Bucket=AWS_S3_BUCKET,
                    Key=saved_key
                )
                logging.debug(f"Successfully copied from {archive_key} to {saved_key}")
                return True, filename
            except Exception as e:
                logging.error(f"Error copying chat file from archive to saved: {e}")
                return False, None
        else:
            # Regular save to archive
            try:
                # Try to get existing content
                existing_obj = s3_client.get_object(Bucket=AWS_S3_BUCKET, Key=archive_key)
                existing_content = existing_obj['Body'].read().decode('utf-8')
                # Append new content
                full_content = existing_content + '\n' + chat_content
            except s3_client.exceptions.NoSuchKey:
                # File doesn't exist yet, use just the new content
                logging.debug(f"File {archive_key} does not exist. Creating new file.")
                full_content = chat_content
            
            # Save the combined content
            s3_client.put_object(
                Bucket=AWS_S3_BUCKET,
                Key=archive_key,
                Body=full_content.encode('utf-8')
            )
            logging.debug(f"Successfully saved to {archive_key}")
            return True, filename
            
    except Exception as e:
        logging.error(f"Error saving chat file {filename}: {e}")
        return False, None

def reload_memory(agent_name, memory_agents, initial_system_prompt):
    """Reload memory from chat history files"""
    previous_chats = load_existing_chats_from_s3(agent_name, memory_agents)
    logging.debug(f"Loaded {len(previous_chats)} chat files for memory")
    
    # Combine all chat content
    all_content = []
    for chat in previous_chats:
        chat_content = []
        for msg in chat['messages']:
            chat_content.append(msg['content'])
        if chat_content:
            all_content.append("\n\n".join(chat_content))
            logging.debug(f"Added chat content from {chat['file']}, length: {len(chat_content[-1])}")
    
    combined_content = "\n\n---\n\n".join(all_content)
    logging.debug(f"Combined content length: {len(combined_content)}")
    
    # Add the content to the system prompt with clear context
    if combined_content:
        new_system_prompt = (
            initial_system_prompt + 
            "\n\n## Previous Chat History\nThe following is a summary of previous chat interactions:\n\n" + 
            combined_content
        )
        logging.debug(f"Final system prompt length: {len(new_system_prompt)}")
    else:
        new_system_prompt = initial_system_prompt
        logging.debug("No chat history to add to system prompt")
    
    return new_system_prompt

def display_help():
    print("\nAvailable commands:")
    print("!help          - Display this help message")
    print("!exit          - Exit the chat")
    print("!clear         - Clear the chat history")
    print("!save          - Save current chat history to S3 saved folder")
    print("!memory        - Toggle memory mode (load chat history)")
    print("!listen        - Enable summary listening")
    print("!listen-all    - Enable all listening modes")
    print("!listen-deep   - Enable summary and insights listening")
    print("!listen-insights - Enable insights listening")
    print("!listen-transcript - Enable transcript listening")
    print("\nStartup flags:")
    print("--memory       - Start with memory mode enabled")
    print("--listen       - Start with summary listening enabled")
    print("--listen-all   - Start with all listening modes enabled")
    print("--listen-deep  - Start with summary and insights listening enabled")
    print("--listen-insights - Start with insights listening enabled")
    print("--listen-transcript - Start with transcript listening enabled")

def format_chat_history(messages):
    chat_content = ""
    for msg in messages:
        if msg["role"] == "user":
            chat_content += f"**User:**\n{msg['content']}\n\n"
        else:
            chat_content += f"**Agent:**\n{msg['content']}\n\n"
    return chat_content



def main():
    global abort_requested
    try:
        # Load configuration
        config = AppConfig.from_env_and_args()
        
        # Setup logging
        setup_logging(config.debug)
        
        # Initialize chat filename with timestamp at session start
        timestamp = datetime.now().strftime('%Y%m%d-T%H%M%S')
        event_id = config.event_id  # Updated from config.event to config.event_id
        current_chat_file = f"chat_D{timestamp}_aID-{config.agent_name}_eID-{event_id}.txt"
        logging.debug(f"Initialized chat filename: {current_chat_file}")
        
        # Initialize last saved message index
        last_saved_index = 0
        
        # Start web interface if requested
        if config.interface_mode in ['web', 'web_only']:
            web_interface = WebChat(config)
            web_thread = web_interface.run(port=config.web_port, debug=config.debug)
            print(f"\nWeb interface available at http://127.0.0.1:{config.web_port}")
            
            if config.interface_mode == 'web_only':
                print("\nRunning in web-only mode. Press Ctrl+C to exit.")
                # In web-only mode, just keep the main thread alive
                try:
                    while True:
                        time.sleep(1)
                except KeyboardInterrupt:
                    print("\nShutting down...")
                    return
        
        # Continue with CLI if not web-only
        if config.interface_mode != 'web_only':
            if config.interface_mode == 'web':
                print("CLI interface also available. Type '!help' for commands.\n")
            print(f"Chat agent '{config.agent_name}' is running. Enter your message or type '!help' for commands.\n")
        
            client = Anthropic(api_key=ANTHROPIC_API_KEY)

            # Initialize conversation with system messages
            conversation_history = []

            # Load base system prompt (keep core instructions here)
            system_prompt = get_latest_system_prompt(config.agent_name)
            if not system_prompt:
                logging.error("Failed to load system prompt")
                sys.exit(1)

            # Add frameworks as system messages
            frameworks = get_latest_frameworks(config.agent_name)
            if frameworks:
                logging.info("Adding frameworks as system message")
                # Split base and agent frameworks if both exist
                framework_parts = frameworks.split("\n\n")
                for i, part in enumerate(framework_parts):
                    source = "_config/frameworks_base" if i == 0 else f"organizations/river/agents/{config.agent_name}/_config/frameworks_aID-{config.agent_name}"
                    framework_msg = {
                        "role": "system",
                        "content": f"=== Frameworks ===\n[Source: {source}]\n{part}"
                    }
                    conversation_history.append(framework_msg)
                    logging.debug(f"Added framework message {i+1}: {len(part)} chars")
            else:
                logging.warning("No frameworks found for agent")
                
            # Add context as system message
            context = get_latest_context(config.agent_name)
            if context:
                logging.info("Adding context as system message")
                context_file = f'organizations/river/_config/context_oID-{config.agent_name}'
                context_msg = {
                    "role": "system",
                    "content": f"=== Context ===\n[Source: {context_file}]\n{context}"
                }
                conversation_history.append(context_msg)
                logging.debug(f"Added context message: {len(context)} chars")
            else:
                logging.warning("No context found for agent")
                
            # Add docs if available
            docs = get_agent_docs(config.agent_name)
            if docs:
                logging.info("Adding documentation as system message")
                docs_path = f'organizations/river/agents/{config.agent_name}/docs/'
                docs_msg = {
                    "role": "system",
                    "content": f"=== Documentation ===\n[Source: {docs_path}]\n{docs}"
                }
                conversation_history.append(docs_msg)
                logging.debug(f"Added documentation message: {len(docs)} chars")
            else:
                logging.warning("No documentation found for agent")

            # Load memory after adding all content
            if config.memory is not None:
                if len(config.memory) == 0:
                    config.memory = [config.agent_name]
                system_prompt = reload_memory(config.agent_name, config.memory, system_prompt)

            # Log final system prompt for verification
            logging.debug("\n=== Final System Prompt ===")
            logging.debug(f"Total length: {len(system_prompt)} chars")
            sections = [s for s in system_prompt.split("\n\n=== ") if s.strip()]
            for section in sections:
                lines = section.split("\n")
                if lines[0].endswith(" ==="):
                    section_name = lines[0].replace("===", "").strip()
                    source_line = next((line for line in lines[1:] if line.strip().startswith("[Source:")), "No source file")
                    content = "\n".join(lines[2:])
                    logging.debug(f"\n=== {section_name} ===")
                    logging.debug(f"{source_line}")
                    logging.debug(f"Content length: {len(content)} chars")
                    logging.debug(f"First 100 chars: {content[:100]}")
                    logging.debug(f"Last 100 chars: {content[-100:]}")

            # Initialize transcript handling
            transcript_state = TranscriptState()
            last_transcript_check = time.time()
            TRANSCRIPT_CHECK_INTERVAL = 5  # seconds
            config.listen_transcript_enabled = config.listen_transcript  # Set from command line arg

            # Only load initial content if --listen-transcript flag was used
            if config.listen_transcript:
                if check_transcript_updates(transcript_state, conversation_history, config.agent_name, config.event_id):
                    print("Initial transcript loaded and listening mode activated")
                    config.listen_transcript_enabled = True
                else:
                    print("No initial transcript found, but listening mode activated")
                last_transcript_check = time.time()

            print("\nUser: ", end='', flush=True)  # Initial prompt
            
            # Main chat loop
            while True:
                try:
                    # Check for transcript updates periodically if enabled
                    current_time = time.time()
                    if config.listen_transcript_enabled and current_time - last_transcript_check > TRANSCRIPT_CHECK_INTERVAL:
                        if check_transcript_updates(transcript_state, conversation_history, config.agent_name, config.event_id):
                            logging.debug("New transcript content added")
                        last_transcript_check = current_time

                    if sys.stdin in select.select([sys.stdin], [], [], 0)[0]:
                        user_input = sys.stdin.readline().strip()
                        
                        if not user_input:
                            print("\nUser: ", end='', flush=True)
                            continue
                        
                        if user_input.startswith('!'):
                            command = user_input[1:].lower()
                            if command == 'exit':
                                break
                            elif command == 'help':
                                display_help()
                                print("\nUser: ", end='', flush=True)
                                continue
                            elif command == 'clear':
                                conversation_history = []
                                print("\nUser: ", end='', flush=True)
                                continue
                            elif command == 'save':
                                # Save chat history to saved folder
                                new_messages = conversation_history[last_saved_index:]
                                if not new_messages:
                                    print("No new messages to save.")
                                    print("\nUser: ", end='', flush=True)
                                    continue
                                
                                chat_content = format_chat_history(new_messages)
                                logging.debug(f"Saving chat to {current_chat_file}")
                                success, _ = save_chat_to_s3(config.agent_name, chat_content, config.event_id, is_saved=False, filename=current_chat_file)
                                
                                if success:
                                    print(f"Chat history saved to {current_chat_file}")
                                    last_saved_index = len(conversation_history)
                                else:
                                    print("Failed to save chat history")
                                print("\nUser: ", end='', flush=True)
                                continue
                            elif command == 'memory':
                                if config.memory is None:
                                    config.memory = [config.agent_name]
                                    system_prompt = reload_memory(config.agent_name, config.memory, system_prompt)
                                    print("Memory mode activated.")
                                else:
                                    config.memory = None
                                    system_prompt = get_latest_system_prompt(config.agent_name)
                                    print("Memory mode deactivated.")
                                print("\nUser: ", end='', flush=True)
                                continue
                            elif command in ['listen', 'listen-all', 'listen-deep', 'listen-insights', 'listen-transcript']:
                                # Enable transcript loading only for relevant commands
                                if command in ['listen', 'listen-all', 'listen-transcript']:
                                    config.listen_transcript_enabled = True
                                    if check_transcript_updates(transcript_state, conversation_history, config.agent_name, config.event_id):
                                        print("Transcript loaded and automatic listening mode activated.")
                                    else:
                                        print("No new transcript content found.")
                                    last_transcript_check = time.time()  # Reset check timer
                                elif command == 'silent':
                                    config.listen_transcript_enabled = False
                                    print("Transcript listening mode deactivated.")

                                # Handle other listen modes
                                if command in ['listen', 'listen-all', 'listen-deep', 'listen-insights']:
                                    # Existing insights/summary loading code...
                                    pass
                                
                                print("\nUser: ", end='', flush=True)
                                continue
                        
                        # Process user message
                        current_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        user_content = f"On {current_timestamp}, user said: {user_input}"
                        conversation_history.append({"role": "user", "content": user_content})
                        
                        try:
                            response = analyze_with_claude(client, conversation_history, system_prompt)
                            if response is None:
                                print("\nUser: ", end='', flush=True)
                                continue
                            conversation_history.append({"role": "assistant", "content": response})
                            
                            # Format and save only the latest message round
                            latest_messages = conversation_history[-2:]  # Get user message and assistant response
                            chat_content = format_chat_history(latest_messages)
                            logging.debug(f"Saving latest message round to {current_chat_file}")
                            success, _ = save_chat_to_s3(config.agent_name, chat_content, event_id=config.event_id, is_saved=False, filename=current_chat_file)
                            
                            if not success:
                                print("Failed to save chat history")
                            
                            print("\nUser: ", end='', flush=True)  # Add prompt for next input
                            
                        except Exception as e:
                            logging.error(f"Error processing message: {e}")
                            print(f"\nError: {e}")
                            print("\nUser: ", end='', flush=True)  # Add prompt even after error
                except (EOFError, KeyboardInterrupt):
                    print("\nExiting the chat.")
                    break

    except Exception as e:
        logging.error(f"Error in main loop: {e}")

if __name__ == '__main__':
    main()
```

File: /Users/neonvoid/Library/Mobile Documents/com~apple~CloudDocs/Documents/Projekt/River/River Resources/Code/magic_chat-local/models.py
```py
from pydantic import BaseModel
from typing import List, Optional, Dict

class KeywordAnalysis(BaseModel):
    keyword: str
    frequency: int
    context: str

class ThemeAnalysis(BaseModel):
    theme: str
    supporting_evidence: str
    related_keywords: List[str]

class ConversationPattern(BaseModel):
    pattern: str
    evidence: str
    impact: str
    frequency: int
    timestamps: List[str]

class LatentNeed(BaseModel):
    need: str
    urgency_score: float
    evidence: str

class OrganizationalNeed(BaseModel):
    need: str
    urgency_score: float
    evidence: str

class LatentContent(BaseModel):
    content: str
    interpretation: str
    confidence_score: float

class EmergingInsight(BaseModel):
    insight: str
    evidence: str
    potential_impact: str

class TrajectoryForecast(BaseModel):
    trajectory: str
    likelihood: float
    implications: str
    timeframe: str

class LeverageOpportunity(BaseModel):
    opportunity: str
    potential_impact: str
    impact_score: float
    effort_score: float
    evidence: str

class SingleLoopLearning(BaseModel):
    explicit_learning: str
    hidden_learning: str
    implications: str

class DoubleLoopLearning(BaseModel):
    explicit_learning: str
    hidden_learning: str
    implications: str

class TripleLoopLearning(BaseModel):
    explicit_learning: str
    hidden_learning: str
    implications: str

class Sovereignty(BaseModel):
    sentience: str
    intelligence: str
    agency: str
    evolution: str

class Integral(BaseModel):
    subjective_perspective: str
    objective_perspective: str
    individual_domain: str
    collective_domain: str
    integral_capacity: float

class InsightsOutput(BaseModel):
    keywords: List[KeywordAnalysis]
    themes: List[ThemeAnalysis]
    conversation_patterns: List[ConversationPattern]
    latent_needs: List[LatentNeed]
    organizational_needs: List[OrganizationalNeed]
    latent_content: List[LatentContent]
    emerging_insights: List[EmergingInsight]
    trajectory_forecasts: List[TrajectoryForecast]
    leverage_opportunities: List[LeverageOpportunity]
    single_loop_learning: List[SingleLoopLearning]
    double_loop_learning: List[DoubleLoopLearning]
    triple_loop_learning: List[TripleLoopLearning]
    sovereignty_level: List[Sovereignty]
    integral_perspective: List[Integral]
```

File: /Users/neonvoid/Library/Mobile Documents/com~apple~CloudDocs/Documents/Projekt/River/River Resources/Code/magic_chat-local/utils/transcript_utils.py
```py
import logging
import boto3
import os
from datetime import datetime

class TranscriptState:
    def __init__(self):
        self.current_key = None
        self.last_position = 0
        self.last_modified = None

def get_latest_transcript_file(agent_name=None, event_id=None, s3_client=None, bucket_name=None):
    """Get the latest transcript file, first from agent's event folder"""
    if s3_client is None:
        s3_client = boto3.client(
            's3',
            region_name=os.getenv('AWS_REGION'),
            aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),
            aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY')
        )
    
    if bucket_name is None:
        bucket_name = os.getenv('AWS_S3_BUCKET')
    
    try:
        # First try agent's event folder
        if agent_name and event_id:
            prefix = f'organizations/river/agents/{agent_name}/events/{event_id}/transcripts/'
            response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix, Delimiter='/')
            
            if 'Contents' in response:
                transcript_files = [
                    obj['Key'] for obj in response['Contents']
                    if obj['Key'].startswith(prefix) and obj['Key'] != prefix
                    and not obj['Key'].replace(prefix, '').strip('/').count('/')
                    and obj['Key'].endswith('.txt')
                ]
                if transcript_files:
                    logging.debug(f"Found {len(transcript_files)} transcript files in agent folder:")
                    for tf in transcript_files:
                        obj = s3_client.head_object(Bucket=bucket_name, Key=tf)
                        logging.debug(f"  - {tf} (Size: {obj['ContentLength']} bytes, Modified: {obj['LastModified']})")
                    
                    latest_file = max(transcript_files, key=lambda x: s3_client.head_object(Bucket=bucket_name, Key=x)['LastModified'])
                    obj = s3_client.head_object(Bucket=bucket_name, Key=latest_file)
                    logging.debug(f"Selected latest transcript in agent folder: {latest_file}")
                    return latest_file
                    
        # Fallback to default transcripts folder
        prefix = '_files/transcripts/'
        response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix, Delimiter='/')
        
        if 'Contents' in response:
            transcript_files = [
                obj['Key'] for obj in response['Contents']
                if obj['Key'].startswith(prefix) and obj['Key'] != prefix
                and not obj['Key'].replace(prefix, '').strip('/').count('/')
                and obj['Key'].endswith('.txt')
            ]
            if transcript_files:
                latest_file = max(transcript_files, key=lambda x: s3_client.head_object(Bucket=bucket_name, Key=x)['LastModified'])
                return latest_file
                
        return None
        
    except Exception as e:
        logging.error(f"Error finding transcript files in S3: {e}")
        return None

def read_new_transcript_content(state, agent_name, event_id, s3_client=None, bucket_name=None):
    """Read only new content from transcript file"""
    try:
        latest_key = get_latest_transcript_file(agent_name, event_id, s3_client, bucket_name)
        if not latest_key:
            logging.debug("No transcript file found")
            return None
            
        if s3_client is None:
            s3_client = boto3.client('s3')
        if bucket_name is None:
            bucket_name = os.getenv('AWS_S3_BUCKET')
            
        response = s3_client.get_object(Bucket=bucket_name, Key=latest_key)
        content = response['Body'].read().decode('utf-8')
        
        if latest_key != state.current_key:
            # New file - read from start
            new_content = content
            state.last_position = len(content)
            logging.debug(f"New transcript file detected, read {len(new_content)} bytes")
        else:
            # Existing file updated - get only new content
            new_content = content[state.last_position:]
            state.last_position = len(content)
            logging.debug(f"Existing file updated, read {len(new_content)} new bytes")
            
        state.current_key = latest_key
        state.last_modified = response['LastModified']
        return new_content
            
    except Exception as e:
        logging.error(f"Error reading transcript: {e}")
        return None
```
</file_contents>

