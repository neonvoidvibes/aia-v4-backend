"""
Canvas view streaming routes.
Handles PTT-to-LLM streaming for the canvas interface.
"""

import os
import json
import logging
from datetime import datetime, timezone
from zoneinfo import ZoneInfo
from flask import jsonify, Response, stream_with_context, g
from gotrue.types import User as SupabaseUser
from anthropic import Anthropic, AnthropicError
from tenacity import RetryError
from utils.s3_utils import get_cached_s3_file, find_file_any_extension, get_objective_function
from utils.api_key_manager import get_api_key
from utils.canvas_analysis_agents import get_or_generate_analysis_doc, get_analysis_status

logger = logging.getLogger(__name__)


def get_agent_specific_prompt_only(agent_name: str) -> str:
    """
    Load ONLY the agent-specific prompt without any base system prompt.
    This ensures canvas doesn't inherit the full taxonomy structure.
    """
    agent_pattern = f'organizations/river/agents/{agent_name}/_config/systemprompt_aID-{agent_name}'
    agent_prompt = get_cached_s3_file(
        cache_key=agent_pattern,
        description=f"agent system prompt for {agent_name}",
        fetch_function=lambda: find_file_any_extension(agent_pattern, f"agent system prompt for {agent_name}")
    )
    if agent_prompt:
        logger.info(f"Loaded agent-specific canvas prompt for '{agent_name}' ({len(agent_prompt)} chars)")
        return agent_prompt
    else:
        logger.warning(f"No agent-specific prompt found for '{agent_name}', using empty string")
        return ""


def get_canvas_base_and_depth_prompt(depth_mode: str) -> str:
    """
    Returns canvas base prompt combined with MLP depth-specific instructions.

    Structure:
    1. Canvas Base (global rules for all depths)
    2. MLP Depth Instructions (mirror/lens/portal specific)

    Args:
        depth_mode: One of 'mirror', 'lens', or 'portal'

    Returns:
        Combined canvas base + depth instructions
    """
    # Canvas Base: Universal rules for all canvas interactions
    canvas_base = """=== CANVAS BASE ===
You are a specialized canvas agent responding on a visual interface using voice input.

YOUR ROLE:
You draw on multiple foundational sources to provide focused, contextual responses:
- OBJECTIVE FUNCTION: Your core purpose and strategic direction
- AGENT CONTEXT: Your specific domain expertise and personality
- ANALYSIS DOCUMENTS: Pre-analyzed insights from transcripts (when available)
- MODE INSTRUCTIONS: How to respond in your current mode (mirror/lens/portal)

Integrate these sources naturally - you're not just answering questions, you're serving the objective while staying true to your agent identity and the current analytical mode.

CORE RULES (apply to ALL responses):
- Keep responses extremely short: 1-3 sentences maximum
- Use conversational, natural language
- Minimize special characters but keep normal punctuation and comma
- NO lists or bullet points allowed
- NO markdown formatting (no **, -, #, etc.)
- Plain text only
- Each response should feel like a single thought

ANALYSIS DOCUMENT USAGE:
- You may receive PREVIOUS ANALYSIS and/or CURRENT ANALYSIS documents below
- These contain pre-analyzed insights from transcripts generated by specialized analysis agents
- CURRENT ANALYSIS is the latest and most relevant - use it as your primary knowledge source
- PREVIOUS ANALYSIS (if present) provides historical context for comparison and reference
- Use these as your primary knowledge for responding in the current mode (mirror/lens/portal)
- If no analysis documents are present, respond based on the user's immediate message only
- Do not mention the analysis documents explicitly to the user

=== END CANVAS BASE ==="""

    # MLP Framework: Mirror/Lens/Portal depth instructions
    mlp_instructions = {
        'mirror': """
=== MIRROR MODE (Edges) ===
Focus: Explicit but peripheral information - the edge cases

Your role is to surface what IS explicitly stated but sits at the margins of the conversation. Notice:
- Minority viewpoints that were voiced
- Side comments and tangential observations
- Outlier perspectives explicitly mentioned
- Peripheral but concrete concerns

Reflect these edge cases back clearly and concisely without interpretation. Use participants exact words when possible.

Example patterns: "One person also noted...", "A less central but mentioned point...", "Someone raised on the side..."
=== END MIRROR MODE ===
""",

        'lens': """
=== LENS MODE (Latent Needs) ===
Focus: Hidden patterns and unspoken requirements

Your role is to identify what the conversation implies about deeper contextual needs. Analyze:
- Recurring themes across different speakers
- Emotional undercurrents and group dynamics
- Systemic issues beneath surface symptoms
- Paradoxes and contradictions
- What's being avoided or protected

Surface these latent needs using questioning analytical language that invites reflection.

Example patterns: "The underlying need seems to be...", "What's not being said might be...", "A deeper dynamic at play..."
=== END LENS MODE ===
""",

        'portal': """
=== PORTAL MODE (Questions) ===
Focus: Emergent possibilities formulated as questions

Your role is to open possibility spaces by asking transformative questions derived from lens-level patterns. Generate:
- Questions that challenge limiting assumptions
- Questions that identify transformation opportunities
- Questions about paradigm shifts
- Questions that predict intervention outcomes

All questions must be traceable to a lens-level pattern or paradox. Frame possibilities as invitations to explore.

Example patterns: "What if you could...", "What might happen if...", "How could this open...", "What would it mean to..."
=== END PORTAL MODE ===
"""
    }

    # Combine canvas base with selected depth mode
    depth_instructions = mlp_instructions.get(depth_mode, mlp_instructions['mirror'])
    return f"{canvas_base}\n\n{depth_instructions}"


def register_canvas_routes(app, anthropic_client, supabase_auth_required):
    """
    Register canvas-related routes to the Flask app.

    Args:
        app: Flask application instance
        anthropic_client: Initialized Anthropic client
        supabase_auth_required: Auth decorator function
    """

    @app.route('/api/canvas/stream', methods=['POST'])
    @supabase_auth_required(agent_required=True)
    def handle_canvas_stream(user: SupabaseUser):
        """
        Handles canvas view streaming requests with Claude 4.5 Sonnet.
        Designed for concise, visually-oriented responses optimized for canvas display.
        """
        logger.info(f"Received POST request to /api/canvas/stream from user: {user.id}")

        try:
            data = g.get('json_data', {})
            if not data or 'transcript' not in data:
                return jsonify({"error": "Missing 'transcript' in request body"}), 400
        except Exception as e:
            logger.error(f"Error accessing request data: {e}")
            return jsonify({"error": "Invalid request data"}), 400

        # Extract request parameters
        agent_name = data.get('agent')
        transcript_text = data.get('transcript', '')
        depth_mode = data.get('depth', 'mirror')  # mirror | lens | portal
        conversation_history = data.get('history', [])  # Array of {role, content} messages
        client_timezone = data.get('timezone', 'UTC')  # Client timezone
        force_refresh_analysis = data.get('forceRefreshAnalysis', False)  # Manual refresh button
        clear_previous_analysis = data.get('clearPrevious', False)  # Clear previous on new context
        event_id = '0000'  # Canvas always uses event 0000
        model_selection = os.getenv("LLM_MODEL_NAME", "claude-sonnet-4-5-20250929")
        temperature = 0.7

        # Get transcript_listen_mode and groups_read_mode from agent settings
        from utils.supabase_client import get_supabase_client
        transcript_listen_mode = 'latest'  # Default
        groups_read_mode = 'none'
        client = get_supabase_client()
        if client:
            try:
                agent_res = client.table("agents").select("transcript_listen_mode, groups_read_mode").eq("name", agent_name).limit(1).execute()
                if agent_res.data and len(agent_res.data) > 0:
                    transcript_listen_mode = agent_res.data[0].get("transcript_listen_mode", "latest")
                    groups_read_mode = agent_res.data[0].get("groups_read_mode", "none")
                    logger.info(f"Canvas: transcript_listen_mode={transcript_listen_mode}, groups_read_mode={groups_read_mode} for {agent_name}")
            except Exception as exc:
                logger.warning(f"Failed to fetch memory settings for agent '{agent_name}': {exc}")
                transcript_listen_mode = 'latest'
                groups_read_mode = 'none'

        # Get per-agent custom API key or fallback to default
        agent_anthropic_key = get_api_key(agent_name, 'anthropic')
        if not agent_anthropic_key:
            logger.error(f"Canvas stream fail: No Anthropic API key available for agent '{agent_name}'.")
            return jsonify({"error": "AI service unavailable"}), 503

        # Create agent-specific Anthropic client
        try:
            agent_anthropic_client = Anthropic(api_key=agent_anthropic_key)
            logger.info(f"Anthropic client initialized for agent '{agent_name}' (custom key: {agent_anthropic_key != os.getenv('ANTHROPIC_API_KEY')})")
        except Exception as e:
            logger.error(f"Failed to initialize Anthropic client for agent '{agent_name}': {e}", exc_info=True)
            return jsonify({"error": "AI service initialization failed"}), 503

        def generate_canvas_stream():
            """Generator for canvas-specific streaming responses."""
            try:
                logger.info(f"Canvas stream started for Agent: {agent_name}, User: {user.id}, Depth: {depth_mode}, Force refresh: {force_refresh_analysis}, Clear previous: {clear_previous_analysis}")

                # Get or generate current and previous analysis documents for this mode
                current_analysis_doc = None
                previous_analysis_doc = None
                try:
                    # Get both current and previous analysis (may generate if needed)
                    current_analysis_doc, previous_analysis_doc = get_or_generate_analysis_doc(
                        agent_name=agent_name,
                        event_id=event_id,
                        depth_mode=depth_mode,
                        force_refresh=force_refresh_analysis,
                        clear_previous=clear_previous_analysis,
                        transcript_listen_mode=transcript_listen_mode,
                        groups_read_mode=groups_read_mode,
                        event_type='shared',  # Canvas typically uses shared context
                        personal_layer=None,  # Canvas doesn't use personal layers for now
                        personal_event_id=None
                    )

                    if current_analysis_doc:
                        logger.info(f"Canvas: Loaded current {depth_mode} analysis ({len(current_analysis_doc)} chars)")
                    if previous_analysis_doc:
                        logger.info(f"Canvas: Loaded previous {depth_mode} analysis ({len(previous_analysis_doc)} chars)")
                    if not current_analysis_doc:
                        logger.info(f"Canvas: No analysis document available for {depth_mode} mode")
                except Exception as analysis_err:
                    logger.error(f"Error getting analysis documents: {analysis_err}", exc_info=True)
                    current_analysis_doc = None
                    previous_analysis_doc = None

                # Build canvas system prompt (lightweight, NO full taxonomy)
                # Structure: Canvas Base + MLP Depth + Objective Function + Analysis Doc (if available) + Agent-Specific + Time
                canvas_base_and_depth = get_canvas_base_and_depth_prompt(depth_mode)
                agent_specific = get_agent_specific_prompt_only(agent_name)

                # Load objective function (agent-specific or global fallback)
                objective_function = None
                try:
                    objective_function = get_objective_function(agent_name) or get_objective_function(None)
                    if objective_function:
                        logger.info(f"Canvas: Loaded objective function for '{agent_name}' ({len(objective_function)} chars)")
                    else:
                        logger.info(f"Canvas: No objective function found for '{agent_name}'")
                except Exception as obj_err:
                    logger.warning(f"Error loading objective function for canvas: {obj_err}")
                    objective_function = None

                # Add current time in user's timezone
                try:
                    user_tz = ZoneInfo(client_timezone)
                    current_user_time = datetime.now(user_tz)
                    current_user_time_str = current_user_time.strftime('%Y-%m-%d %H:%M:%S %Z')
                    tz_abbr = current_user_time.strftime('%Z')
                except Exception as e:
                    logger.warning(f"Invalid timezone '{client_timezone}', falling back to UTC: {e}")
                    current_user_time_str = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')
                    tz_abbr = 'UTC'

                time_section = f"\n\n=== CURRENT TIME ===\nCurrent date and time: {current_user_time_str} (user's local timezone: {client_timezone})\n=== END CURRENT TIME ==="

                # Combine: Objective → Agent → Canvas Base + Depth → Previous Analysis → Current Analysis → Time
                # (Tree structure: roots → stem → trunk → branches → leaves)
                system_prompt = ""

                # 1. Objective function (roots - why you exist)
                if objective_function:
                    system_prompt += f"=== OBJECTIVE FUNCTION ===\n{objective_function}\n=== END OBJECTIVE FUNCTION ==="

                # 2. Agent context (stem - who you are)
                if agent_specific:
                    system_prompt += f"\n\n=== AGENT CONTEXT ===\n{agent_specific}\n=== END AGENT CONTEXT ==="

                # 3. Canvas base + MLP depth (trunk - how you operate)
                system_prompt += f"\n\n{canvas_base_and_depth}"

                # 4. Previous analysis (branches - historical context)
                if previous_analysis_doc:
                    system_prompt += f"\n\n=== PREVIOUS ANALYSIS ===\n{previous_analysis_doc}\n=== END PREVIOUS ANALYSIS ==="

                # 5. Current analysis (branches - fresh content)
                if current_analysis_doc:
                    system_prompt += f"\n\n=== CURRENT ANALYSIS ===\n{current_analysis_doc}\n=== END CURRENT ANALYSIS ==="

                # 6. Current time (leaves - immediate moment)
                system_prompt += time_section

                # Build prompt type description for logging (matches tree order)
                prompt_components = []
                if objective_function:
                    prompt_components.append("objective")
                if agent_specific:
                    prompt_components.append("agent")
                prompt_components.extend(["base", "depth"])

                analysis_status = []
                if previous_analysis_doc:
                    analysis_status.append("previous")
                if current_analysis_doc:
                    analysis_status.append("current")
                if analysis_status:
                    prompt_components.append(f"analysis({'+'.join(analysis_status)})")
                else:
                    prompt_components.append("analysis(none)")

                prompt_components.append("time")
                prompt_type = "+".join(prompt_components)
                logger.info(f"Canvas system prompt built: {len(system_prompt)} chars ({prompt_type})")

                # Build messages with conversation history
                messages = []
                if conversation_history:
                    messages.extend(conversation_history)
                    logger.info(f"Canvas: Using conversation history with {len(conversation_history)} messages")
                else:
                    logger.info("Canvas: No conversation history provided")

                # Add current user message
                messages.append({"role": "user", "content": transcript_text})

                logger.info(f"Calling Anthropic API for canvas stream (model: {model_selection}, depth: {depth_mode}, total messages: {len(messages)})")

                # Stream from Anthropic using agent-specific client
                with agent_anthropic_client.messages.stream(
                    model=model_selection,
                    max_tokens=4096,
                    temperature=temperature,
                    system=system_prompt,
                    messages=messages
                ) as stream:
                    for chunk in stream.text_stream:
                        if chunk:
                            yield f"data: {json.dumps({'delta': chunk})}\n\n"

                # Send completion signal
                yield f"data: {json.dumps({'done': True})}\n\n"
                logger.info(f"Canvas stream completed successfully for agent {agent_name}")

            except (AnthropicError, RetryError) as e:
                logger.error(f"Anthropic API error in canvas stream: {e}", exc_info=True)
                yield f"data: {json.dumps({'error': f'AI service error: {str(e)}'})}\n\n"
            except Exception as e:
                logger.error(f"Error in canvas generate_stream: {e}", exc_info=True)
                yield f"data: {json.dumps({'error': 'An internal server error occurred during the stream.'})}\n\n"

        return Response(stream_with_context(generate_canvas_stream()), mimetype='text/event-stream')

    @app.route('/api/canvas/analysis/status', methods=['GET'])
    @supabase_auth_required(agent_required=True)
    def get_canvas_analysis_status(user: SupabaseUser):
        """
        Get analysis status for the canvas interface.
        Returns status for the currently selected mode.
        """
        try:
            agent_name = g.get('agent_name')
            depth_mode = g.get('json_data', {}).get('depth', 'mirror')
            event_id = '0000'

            if not agent_name:
                return jsonify({"error": "Missing agent parameter"}), 400

            status = get_analysis_status(agent_name, event_id, depth_mode)
            return jsonify(status)

        except Exception as e:
            logger.error(f"Error getting canvas analysis status: {e}", exc_info=True)
            return jsonify({"error": "Failed to get analysis status"}), 500

    @app.route('/api/canvas/analysis/refresh', methods=['POST'])
    @supabase_auth_required(agent_required=True)
    def refresh_canvas_analysis(user: SupabaseUser):
        """
        Manually trigger refresh of all analysis documents (mirror, lens, portal).
        This is called when the user clicks the sparkles icon.
        """
        logger.info(f"Received POST request to /api/canvas/analysis/refresh from user: {user.id}")

        try:
            data = g.get('json_data', {})
            agent_name = data.get('agent')
            clear_previous = data.get('clearPrevious', False)  # Clear previous on new context
            event_id = '0000'

            if not agent_name:
                return jsonify({"error": "Missing agent parameter"}), 400

            # Get transcript_listen_mode and groups_read_mode from agent settings
            from utils.supabase_client import get_supabase_client
            transcript_listen_mode = 'latest'
            groups_read_mode = 'none'
            client = get_supabase_client()
            if client:
                try:
                    agent_res = client.table("agents").select("transcript_listen_mode, groups_read_mode").eq("name", agent_name).limit(1).execute()
                    if agent_res.data and len(agent_res.data) > 0:
                        transcript_listen_mode = agent_res.data[0].get("transcript_listen_mode", "latest")
                        groups_read_mode = agent_res.data[0].get("groups_read_mode", "none")
                except Exception as exc:
                    logger.warning(f"Failed to fetch memory settings: {exc}")
                    transcript_listen_mode = 'latest'
                    groups_read_mode = 'none'

            # Refresh all three modes in parallel (for now, sequential is simpler)
            results = {}
            for mode in ['mirror', 'lens', 'portal']:
                try:
                    logger.info(f"Refreshing {mode} analysis for {agent_name} (clear_previous={clear_previous})")
                    doc, _ = get_or_generate_analysis_doc(
                        agent_name=agent_name,
                        event_id=event_id,
                        depth_mode=mode,
                        force_refresh=True,  # Force refresh
                        clear_previous=clear_previous,  # Clear previous if requested
                        transcript_listen_mode=transcript_listen_mode,
                        groups_read_mode=groups_read_mode,
                        event_type='shared',
                        personal_layer=None,
                        personal_event_id=None
                    )
                    results[mode] = {
                        'success': doc is not None,
                        'length': len(doc) if doc else 0
                    }
                    if doc:
                        logger.info(f"Successfully refreshed {mode} analysis ({len(doc)} chars)")
                    else:
                        logger.warning(f"Failed to refresh {mode} analysis")
                except Exception as e:
                    logger.error(f"Error refreshing {mode} analysis: {e}", exc_info=True)
                    results[mode] = {'success': False, 'error': str(e)}

            # Get status for response
            status = get_analysis_status(agent_name, event_id, 'mirror')  # Can use any mode

            return jsonify({
                'success': True,
                'results': results,
                'timestamp': datetime.now(timezone.utc).isoformat()
            })

        except Exception as e:
            logger.error(f"Error refreshing canvas analysis: {e}", exc_info=True)
            return jsonify({"error": "Failed to refresh analysis"}), 500
